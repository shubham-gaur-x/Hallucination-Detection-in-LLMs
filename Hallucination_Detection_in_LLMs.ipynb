{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d4ada7",
   "metadata": {},
   "source": [
    "# Hallucination Detection with RAG\n",
    "This notebook implements hallucination detection using the FEVER dataset, including RAG and LLM-based verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c349ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Hallucination Detection System with RAG\n",
    "# This code implements a complete pipeline for hallucination detection using the FEVER dataset\n",
    "# with class balancing and Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# For ML and NLP processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import spacy\n",
    "\n",
    "# For RAG components\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "import openai\n",
    "\n",
    "# Create a global cache dictionary and path\n",
    "CACHE_FILE = \"/Users/shubhamgaur/Desktop/NU/Sem4/IR/Project/Milestone2/llm_response_cache.json\"\n",
    "\n",
    "# Load existing cache (if available)\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"r\") as f:\n",
    "        llm_cache = json.load(f)\n",
    "else:\n",
    "    llm_cache = {}\n",
    "\n",
    "# Load spaCy model for entity extraction\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    print(\"Installing spaCy model...\")\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Enable tqdm for Pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3667dd",
   "metadata": {},
   "source": [
    "## # Part 1: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9b774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad72c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the local FEVER dataset file\n",
    "FILE_PATH = \"/Users/shubhamgaur/Desktop/NU/Sem4/IR/Project/Milestone2/train.jsonl\"\n",
    "\n",
    "def load_fever_dataset(file_path):\n",
    "    \"\"\"Load FEVER dataset from JSONL file.\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text but preserve important information.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Less aggressive cleaning to preserve semantic meaning\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text inside brackets\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    # Don't remove digits as they can be important\n",
    "    # Don't remove all punctuation as it can change meaning\n",
    "    text = re.sub(r'[^\\w\\s.,;?!-]', '', text)  # Keep some punctuation\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def format_evidence(evidence):\n",
    "    \"\"\"Format evidence for better processing.\"\"\"\n",
    "    if not evidence:\n",
    "        return \"No evidence provided.\"\n",
    "    \n",
    "    # Handle nested list structure\n",
    "    if isinstance(evidence, list):\n",
    "        # Flatten list and convert all items to strings\n",
    "        flattened = []\n",
    "        for item in evidence:\n",
    "            if isinstance(item, list):\n",
    "                for subitem in item:\n",
    "                    if isinstance(subitem, list) and len(subitem) >= 3:\n",
    "                        # FEVER evidence is often [doc_id, sent_id, text]\n",
    "                        if subitem[2] is not None:\n",
    "                            flattened.append(str(subitem[2]))\n",
    "                    else:\n",
    "                        if subitem is not None:\n",
    "                            flattened.append(str(subitem))\n",
    "            elif item is not None:\n",
    "                flattened.append(str(item))\n",
    "        \n",
    "        return \" \".join(flattened) if flattened else \"No relevant evidence found.\"\n",
    "    \n",
    "    return str(evidence)\n",
    "\n",
    "def extract_entities(text):\n",
    "    \"\"\"Extract named entities from text.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return set([ent.text.lower() for ent in doc.ents])\n",
    "\n",
    "def entity_overlap(claim, evidence):\n",
    "    \"\"\"Calculate entity overlap between claim and evidence.\"\"\"\n",
    "    claim_entities = extract_entities(claim)\n",
    "    evidence_entities = extract_entities(evidence)\n",
    "    \n",
    "    if not claim_entities:\n",
    "        return 0.0\n",
    "    \n",
    "    overlap = claim_entities.intersection(evidence_entities)\n",
    "    return len(overlap) / len(claim_entities)\n",
    "\n",
    "def semantic_similarity(claim, evidence, model):\n",
    "    \"\"\"Calculate semantic similarity between claim and evidence.\"\"\"\n",
    "    claim_emb = model.encode([claim])[0]\n",
    "    evidence_emb = model.encode([evidence])[0]\n",
    "    return torch.nn.functional.cosine_similarity(\n",
    "        torch.tensor(claim_emb).unsqueeze(0),\n",
    "        torch.tensor(evidence_emb).unsqueeze(0)\n",
    "    ).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f9422",
   "metadata": {},
   "source": [
    "## # Part 2: Main Data Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70878aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fever_data(file_path, balanced_sampling=True):\n",
    "    \"\"\"Process FEVER dataset with option for balanced sampling.\"\"\"\n",
    "    print(\"Loading FEVER dataset...\")\n",
    "    df_fever = load_fever_dataset(file_path)\n",
    "    print(f\"Dataset loaded with {len(df_fever)} entries.\")\n",
    "    \n",
    "    # Select necessary columns\n",
    "    columns_to_keep = ['id', 'claim', 'evidence', 'label']\n",
    "    df_fever = df_fever[columns_to_keep]\n",
    "    \n",
    "    # Handle missing values\n",
    "    df_fever.dropna(inplace=True)\n",
    "    \n",
    "    # Convert labels to numeric encoding\n",
    "    label_mapping = {\"SUPPORTS\": 2, \"REFUTES\": 1, \"NOT ENOUGH INFO\": 0}\n",
    "    df_fever['label'] = df_fever['label'].map(label_mapping)\n",
    "    \n",
    "    # Clean text\n",
    "    print(\"Cleaning text data...\")\n",
    "    df_fever['claim_cleaned'] = df_fever['claim'].apply(clean_text)\n",
    "    \n",
    "    # Format evidence properly\n",
    "    print(\"Formatting evidence...\")\n",
    "    df_fever['evidence_cleaned'] = df_fever['evidence'].apply(format_evidence)\n",
    "    \n",
    "    # Remove Duplicate Claims\n",
    "    df_fever.drop_duplicates(subset=['claim'], inplace=True)\n",
    "    \n",
    "    # Print dataset statistics\n",
    "    print(\"\\nDataset Statistics:\")\n",
    "    print(f\"Total Claims: {len(df_fever)}\")\n",
    "    print(df_fever['label'].value_counts())\n",
    "    \n",
    "    # Balanced sampling if requested\n",
    "    if balanced_sampling:\n",
    "        print(\"\\nPerforming balanced sampling...\")\n",
    "        # Find the class with minimum samples\n",
    "        min_class_count = df_fever['label'].value_counts().min()\n",
    "        \n",
    "        # Sample equal number from each class\n",
    "        df_supports = df_fever[df_fever['label'] == 2].sample(min_class_count, random_state=42)\n",
    "        df_refutes = df_fever[df_fever['label'] == 1].sample(min_class_count, random_state=42)\n",
    "        df_nei = df_fever[df_fever['label'] == 0].sample(min_class_count, random_state=42)\n",
    "        \n",
    "        # Combine balanced dataset\n",
    "        df_balanced = pd.concat([df_supports, df_refutes, df_nei])\n",
    "        df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        print(\"\\nBalanced Dataset Statistics:\")\n",
    "        print(f\"Total Claims: {len(df_balanced)}\")\n",
    "        print(df_balanced['label'].value_counts())\n",
    "        \n",
    "        return df_balanced\n",
    "    \n",
    "    return df_fever\n",
    "\n",
    "def create_train_val_test_split(df):\n",
    "    \"\"\"Split dataset into train, validation, and test sets.\"\"\"\n",
    "    print(\"Splitting data into train, validation, and test sets...\")\n",
    "    \n",
    "    # Splitting with stratification to maintain class distribution\n",
    "    train_data, temp_data = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
    "    val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42, stratify=temp_data['label'])\n",
    "    \n",
    "    print(f\"Training set size: {len(train_data)}\")\n",
    "    print(f\"Validation set size: {len(val_data)}\")\n",
    "    print(f\"Test set size: {len(test_data)}\")\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def add_nlp_features(train_data, val_data, test_data):\n",
    "    \"\"\"Add NLP features for improved classification.\"\"\"\n",
    "    print(\"Adding NLP features...\")\n",
    "    \n",
    "    # Load the sentence transformer model\n",
    "    sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    # Add similarity feature\n",
    "    print(\"Calculating semantic similarities...\")\n",
    "    train_data['similarity_score'] = train_data.progress_apply(\n",
    "        lambda x: semantic_similarity(x['claim_cleaned'], x['evidence_cleaned'], sentence_model), \n",
    "        axis=1\n",
    "    )\n",
    "    val_data['similarity_score'] = val_data.progress_apply(\n",
    "        lambda x: semantic_similarity(x['claim_cleaned'], x['evidence_cleaned'], sentence_model), \n",
    "        axis=1\n",
    "    )\n",
    "    test_data['similarity_score'] = test_data.progress_apply(\n",
    "        lambda x: semantic_similarity(x['claim_cleaned'], x['evidence_cleaned'], sentence_model), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Add entity overlap feature\n",
    "    print(\"Calculating entity overlaps...\")\n",
    "    train_data['entity_overlap'] = train_data.progress_apply(\n",
    "        lambda x: entity_overlap(x['claim_cleaned'], x['evidence_cleaned']), \n",
    "        axis=1\n",
    "    )\n",
    "    val_data['entity_overlap'] = val_data.progress_apply(\n",
    "        lambda x: entity_overlap(x['claim_cleaned'], x['evidence_cleaned']), \n",
    "        axis=1\n",
    "    )\n",
    "    test_data['entity_overlap'] = test_data.progress_apply(\n",
    "        lambda x: entity_overlap(x['claim_cleaned'], x['evidence_cleaned']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Add claim length feature\n",
    "    train_data['claim_length'] = train_data['claim_cleaned'].apply(lambda x: len(x.split()))\n",
    "    val_data['claim_length'] = val_data['claim_cleaned'].apply(lambda x: len(x.split()))\n",
    "    test_data['claim_length'] = test_data['claim_cleaned'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    # Add evidence length feature\n",
    "    train_data['evidence_length'] = train_data['evidence_cleaned'].apply(lambda x: len(x.split()))\n",
    "    val_data['evidence_length'] = val_data['evidence_cleaned'].apply(lambda x: len(x.split()))\n",
    "    test_data['evidence_length'] = test_data['evidence_cleaned'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac8e26",
   "metadata": {},
   "source": [
    "## # Part 3: RAG Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92416243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529100c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_rag_system(train_data):\n",
    "    \"\"\"Set up a Retrieval-Augmented Generation system using evidence in the training data.\"\"\"\n",
    "    print(\"Setting up RAG system...\")\n",
    "    \n",
    "    # Create a corpus of evidence documents\n",
    "    documents = []\n",
    "    \n",
    "    for idx, row in tqdm(train_data.iterrows(), total=len(train_data)):\n",
    "        # Use each evidence as a document with metadata about the claim and label\n",
    "        documents.append(\n",
    "            Document(\n",
    "                page_content=row['evidence_cleaned'],\n",
    "                metadata={\n",
    "                    'claim_id': row['id'] if 'id' in row else idx,\n",
    "                    'claim': row['claim_cleaned'],\n",
    "                    'label': row['label']\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Split documents for better retrieval\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50\n",
    "    )\n",
    "    split_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"Created {len(split_documents)} document chunks for RAG\")\n",
    "    \n",
    "    # Create vector embeddings\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Create vector store\n",
    "    vector_store = FAISS.from_documents(split_documents, embeddings)\n",
    "    \n",
    "    print(\"RAG system setup complete\")\n",
    "    return vector_store\n",
    "\n",
    "def retrieve_relevant_evidence(vector_store, claim, k=3):\n",
    "    \"\"\"Retrieve relevant evidence for a claim using RAG.\"\"\"\n",
    "    # Search for similar evidence\n",
    "    relevant_docs = vector_store.similarity_search(claim, k=k)\n",
    "    \n",
    "    # Extract evidence and metadata\n",
    "    results = []\n",
    "    for doc in relevant_docs:\n",
    "        results.append({\n",
    "            'evidence': doc.page_content,\n",
    "            'claim': doc.metadata.get('claim', ''),\n",
    "            'label': doc.metadata.get('label', '')\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def augment_evidence_with_rag(test_data, vector_store):\n",
    "    \"\"\"Augment test data with additional evidence from RAG.\"\"\"\n",
    "    print(\"Augmenting test data with RAG-retrieved evidence...\")\n",
    "    \n",
    "    enhanced_evidence = []\n",
    "    enhanced_labels = []\n",
    "    \n",
    "    for idx, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        # Get original evidence and claim\n",
    "        original_evidence = row['evidence_cleaned']\n",
    "        claim = row['claim_cleaned']\n",
    "        \n",
    "        # Retrieve relevant evidence\n",
    "        retrieved_docs = retrieve_relevant_evidence(vector_store, claim, k=3)\n",
    "        \n",
    "        # Combine original and retrieved evidence\n",
    "        additional_evidence = [doc['evidence'] for doc in retrieved_docs]\n",
    "        combined_evidence = original_evidence + \" \" + \" \".join(additional_evidence)\n",
    "        \n",
    "        # Also collect the labels from the retrieved evidence for potential use\n",
    "        retrieved_labels = [doc['label'] for doc in retrieved_docs]\n",
    "        \n",
    "        enhanced_evidence.append(combined_evidence)\n",
    "        enhanced_labels.append(retrieved_labels)\n",
    "    \n",
    "    test_data['rag_evidence'] = enhanced_evidence\n",
    "    test_data['retrieved_labels'] = enhanced_labels\n",
    "    \n",
    "    # Update similarity and entity overlap using augmented evidence\n",
    "    sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    test_data['rag_similarity'] = test_data.progress_apply(\n",
    "        lambda x: semantic_similarity(x['claim_cleaned'], x['rag_evidence'], sentence_model), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    test_data['rag_entity_overlap'] = test_data.progress_apply(\n",
    "        lambda x: entity_overlap(x['claim_cleaned'], x['rag_evidence']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5078b15",
   "metadata": {},
   "source": [
    "## # Part 4: LLM Integration and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84b156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1385ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_prompt(claim, evidence):\n",
    "    \"\"\"Create an enhanced prompt for LLM verification.\"\"\"\n",
    "    return f\"\"\"\n",
    "Task: Fact verification - determine if the claim is supported by, refuted by, or lacks sufficient evidence.\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Evidence: {evidence}\n",
    "\n",
    "Steps to follow:\n",
    "1. Analyze the key entities and relationships in the claim\n",
    "2. Check if these entities and relationships are present in the evidence\n",
    "3. Determine if the evidence directly supports or contradicts the claim\n",
    "4. If evidence is insufficient to make a determination, indicate so\n",
    "\n",
    "Based on your analysis, classify as one of:\n",
    "- \"Supported\" (evidence confirms the claim)\n",
    "- \"Refuted\" (evidence contradicts the claim) \n",
    "- \"Not Enough Information\" (evidence is insufficient)\n",
    "\n",
    "Classification: \n",
    "\"\"\"\n",
    "\n",
    "def create_rag_prompt(claim, evidence, retrieved_evidence):\n",
    "    \"\"\"Create a prompt that incorporates RAG-retrieved evidence.\"\"\"\n",
    "    return f\"\"\"\n",
    "Task: Fact verification - determine if the claim is supported by, refuted by, or lacks sufficient evidence.\n",
    "\n",
    "Claim: {claim}\n",
    "\n",
    "Primary Evidence: {evidence}\n",
    "\n",
    "Additional Related Evidence:\n",
    "{retrieved_evidence}\n",
    "\n",
    "Based on ALL the evidence provided (both primary and additional), classify the claim as one of:\n",
    "- \"Supported\" (evidence confirms the claim)\n",
    "- \"Refuted\" (evidence contradicts the claim) \n",
    "- \"Not Enough Information\" (evidence is insufficient)\n",
    "\n",
    "Classification: \n",
    "\"\"\"\n",
    "\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "\n",
    "import openai\n",
    "\n",
    "def query_llm_with_retry(prompt, model=\"gpt-4\", max_retries=3, delay=5):\n",
    "    if prompt in llm_cache:\n",
    "        return llm_cache[prompt]  # Use cached result\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            content = response['choices'][0]['message']['content'].strip()\n",
    "            llm_cache[prompt] = content\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(delay)\n",
    "    return \"API Error\"\n",
    "\n",
    "\n",
    "def parse_llm_response(response):\n",
    "    \"\"\"Convert LLM text response to label.\"\"\"\n",
    "    response = response.lower()\n",
    "    if 'supported' in response or 'support' in response:\n",
    "        return 2\n",
    "    elif 'refuted' in response or 'refute' in response or 'contradict' in response:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0  # Not Enough Information\n",
    "\n",
    "def evaluate_standard_approach_batched(test_data, sample_size=500, batch_size=20):\n",
    "    print(f\"Evaluating standard LLM approach with sample size {sample_size} using batch size {batch_size}...\")\n",
    "\n",
    "    # Sample from test data\n",
    "    sample_data = test_data.sample(sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Generate prompts\n",
    "    sample_data['standard_prompt'] = sample_data.apply(\n",
    "        lambda x: create_enhanced_prompt(x['claim_cleaned'], x['evidence_cleaned']), axis=1\n",
    "    )\n",
    "\n",
    "    # Store predictions\n",
    "    llm_responses = []\n",
    "\n",
    "    for i in tqdm(range(0, sample_size, batch_size)):\n",
    "        batch = sample_data.iloc[i:i+batch_size]\n",
    "        for prompt in batch['standard_prompt']:\n",
    "            response = query_llm_with_retry(prompt)\n",
    "            llm_responses.append(response)\n",
    "\n",
    "    sample_data['llm_response'] = llm_responses\n",
    "    sample_data['llm_pred'] = sample_data['llm_response'].apply(parse_llm_response)\n",
    "\n",
    "    accuracy = accuracy_score(sample_data['label'], sample_data['llm_pred'])\n",
    "    report = classification_report(sample_data['label'], sample_data['llm_pred'])\n",
    "\n",
    "    print(f\"\\nStandard approach accuracy (sample size {sample_size}): {accuracy:.4f}\")\n",
    "    print(report)\n",
    "\n",
    "    return sample_data, accuracy\n",
    "\n",
    "def evaluate_rag_approach_batched(test_data, sample_size=500, batch_size=20):\n",
    "    print(f\"Evaluating RAG-enhanced LLM approach with sample size {sample_size} using batch size {batch_size}...\")\n",
    "\n",
    "    sample_data = test_data.sample(sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    # Generate prompts\n",
    "    sample_data['rag_prompt'] = sample_data.apply(\n",
    "        lambda x: create_rag_prompt(\n",
    "            x['claim_cleaned'],\n",
    "            x['evidence_cleaned'],\n",
    "            x['rag_evidence'] if 'rag_evidence' in x else ''\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Store responses\n",
    "    rag_llm_responses = []\n",
    "\n",
    "    for i in tqdm(range(0, sample_size, batch_size)):\n",
    "        batch = sample_data.iloc[i:i+batch_size]\n",
    "        for prompt in batch['rag_prompt']:\n",
    "            response = query_llm_with_retry(prompt)\n",
    "            rag_llm_responses.append(response)\n",
    "\n",
    "    sample_data['rag_llm_response'] = rag_llm_responses\n",
    "    sample_data['rag_llm_pred'] = sample_data['rag_llm_response'].apply(parse_llm_response)\n",
    "\n",
    "    accuracy = accuracy_score(sample_data['label'], sample_data['rag_llm_pred'])\n",
    "    report = classification_report(sample_data['label'], sample_data['rag_llm_pred'])\n",
    "\n",
    "    print(f\"\\nRAG-enhanced approach accuracy (sample size {sample_size}): {accuracy:.4f}\")\n",
    "    print(report)\n",
    "\n",
    "    return sample_data, accuracy\n",
    "\n",
    "def train_ml_model(train_data, val_data):\n",
    "    \"\"\"Train a machine learning model for hallucination detection.\"\"\"\n",
    "    print(\"Training ML model...\")\n",
    "\n",
    "    # Prepare features\n",
    "    X_train = train_data[['claim_cleaned', 'evidence_cleaned', 'similarity_score', 'entity_overlap', 'claim_length', 'evidence_length']]\n",
    "    y_train = train_data['label']\n",
    "    X_val = val_data[['claim_cleaned', 'evidence_cleaned', 'similarity_score', 'entity_overlap', 'claim_length', 'evidence_length']]\n",
    "    y_val = val_data['label']\n",
    "\n",
    "    # Custom transformers\n",
    "    class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, column_name):\n",
    "            self.column_name = column_name\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            return X[self.column_name]\n",
    "\n",
    "    class NumericFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, columns):\n",
    "            self.columns = columns\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            return X[self.columns].values\n",
    "\n",
    "    # Create feature pipeline\n",
    "    features = FeatureUnion([\n",
    "        ('claim_tfidf', Pipeline([\n",
    "            ('selector', ColumnSelector('claim_cleaned')),\n",
    "            ('tfidf', TfidfVectorizer(max_features=1000))\n",
    "        ])),\n",
    "        ('evidence_tfidf', Pipeline([\n",
    "            ('selector', ColumnSelector('evidence_cleaned')),\n",
    "            ('tfidf', TfidfVectorizer(max_features=1000))\n",
    "        ])),\n",
    "        ('numeric_features', NumericFeatureExtractor(['similarity_score', 'entity_overlap', 'claim_length', 'evidence_length']))\n",
    "    ])\n",
    "\n",
    "    # Create and train random forest model\n",
    "    rf_model = Pipeline([\n",
    "        ('features', features),\n",
    "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "    ])\n",
    "\n",
    "    print(\"Fitting model...\")\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Validate\n",
    "    val_pred = rf_model.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "\n",
    "    print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return rf_model\n",
    "\n",
    "def ensemble_prediction(ml_pred, llm_pred, confidence=0.7):\n",
    "    \"\"\"Create ensemble prediction combining ML and LLM approaches.\"\"\"\n",
    "    # If LLM and ML agree, return their prediction\n",
    "    if ml_pred == llm_pred:\n",
    "        return ml_pred\n",
    "    \n",
    "    # If they disagree, trust LLM more (can be adjusted)\n",
    "    if confidence > 0.5:\n",
    "        return llm_pred\n",
    "    else:\n",
    "        return ml_pred\n",
    "\n",
    "def evaluate_ensemble_approach_batched(test_data, ml_model, rag_results, sample_size=500):\n",
    "    \"\"\"Evaluate ensemble approach combining ML model and RAG-enhanced LLM.\"\"\"\n",
    "    print(f\"Evaluating Ensemble approach with sample size {sample_size}...\")\n",
    "\n",
    "    # Ensure same sample as used in rag_results\n",
    "    sample_data = rag_results.copy().reset_index(drop=True)\n",
    "\n",
    "    # Get ML model predictions\n",
    "    X_test_sample = sample_data[['claim_cleaned', 'evidence_cleaned', 'similarity_score',\n",
    "                                 'entity_overlap', 'claim_length', 'evidence_length']]\n",
    "    ml_preds = ml_model.predict(X_test_sample)\n",
    "\n",
    "    sample_data['ml_pred'] = ml_preds\n",
    "\n",
    "    # Combine predictions using confidence logic (LLM favored)\n",
    "    sample_data['ensemble_pred'] = sample_data.apply(\n",
    "        lambda x: ensemble_prediction(x['ml_pred'], x['rag_llm_pred']), axis=1\n",
    "    )\n",
    "\n",
    "    accuracy = accuracy_score(sample_data['label'], sample_data['ensemble_pred'])\n",
    "    report = classification_report(sample_data['label'], sample_data['ensemble_pred'])\n",
    "\n",
    "    print(f\"\\nEnsemble approach accuracy (sample size {sample_size}): {accuracy:.4f}\")\n",
    "    print(report)\n",
    "\n",
    "    return sample_data, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ae2c4a",
   "metadata": {},
   "source": [
    "### XGBoost Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2be5e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Global Custom Transformers (move out of function)\n",
    "# =========================\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.column_name]\n",
    "\n",
    "class NumericFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.columns].values\n",
    "\n",
    "# =========================\n",
    "# Train Function\n",
    "# =========================\n",
    "\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_xgboost_model(train_data, val_data, model_save_path=\"hallucination_xgb_model.json\", feature_save_path=\"hallucination_feature_pipeline.pkl\"):\n",
    "    print(\"Training XGBoost model...\")\n",
    "\n",
    "    # Prepare features\n",
    "    X_train = train_data[['claim_cleaned', 'evidence_cleaned', 'similarity_score', 'entity_overlap', 'claim_length', 'evidence_length']]\n",
    "    y_train = train_data['label']\n",
    "    X_val = val_data[['claim_cleaned', 'evidence_cleaned', 'similarity_score', 'entity_overlap', 'claim_length', 'evidence_length']]\n",
    "    y_val = val_data['label']\n",
    "\n",
    "    # ðŸ”¥ Map labels from {-1, 0, 1} âž” {0, 1, 2}\n",
    "    label_mapping = {-1: 0, 0: 1, 1: 2}\n",
    "    y_train = y_train.map(label_mapping)\n",
    "    y_val = y_val.map(label_mapping)\n",
    "\n",
    "    # Feature pipeline\n",
    "    features = FeatureUnion([\n",
    "        ('claim_tfidf', Pipeline([\n",
    "            ('selector', ColumnSelector('claim_cleaned')),\n",
    "            ('tfidf', TfidfVectorizer(max_features=1000))\n",
    "        ])),\n",
    "        ('evidence_tfidf', Pipeline([\n",
    "            ('selector', ColumnSelector('evidence_cleaned')),\n",
    "            ('tfidf', TfidfVectorizer(max_features=1000))\n",
    "        ])),\n",
    "        ('numeric_features', NumericFeatureExtractor(['similarity_score', 'entity_overlap', 'claim_length', 'evidence_length']))\n",
    "    ])\n",
    "\n",
    "    # Split into training and monitoring (for early stopping)\n",
    "    X_train_final, X_train_monitor, y_train_final, y_train_monitor = train_test_split(\n",
    "        X_train, y_train, test_size=0.1, random_state=42, stratify=y_train\n",
    "    )\n",
    "\n",
    "    print(\"Fitting feature pipeline...\")\n",
    "    features.fit(X_train_final)\n",
    "\n",
    "    # XGBoost model\n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"mlogloss\"\n",
    "    )\n",
    "\n",
    "    print(\"Fitting XGBoost model with early stopping...\")\n",
    "    xgb_clf.fit(\n",
    "        features.transform(X_train_final),\n",
    "        y_train_final,\n",
    "        eval_set=[(features.transform(X_train_monitor), y_train_monitor)],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Save model and feature pipeline\n",
    "    print(f\"Saving XGBoost model to {model_save_path}\")\n",
    "    xgb_clf.save_model(model_save_path)\n",
    "\n",
    "    print(f\"Saving feature pipeline to {feature_save_path}\")\n",
    "    with open(feature_save_path, \"wb\") as f:\n",
    "        pickle.dump(features, f)\n",
    "\n",
    "    # Validation evaluation\n",
    "    val_pred = xgb_clf.predict(features.transform(X_val))\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "    print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return features, xgb_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c2ac9",
   "metadata": {},
   "source": [
    "### Load and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13c2a48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost model saved to hallucination_xgb_model.json\n",
      "Feature pipeline saved to hallucination_feature_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save trained XGBoost model\n",
    "xgb_model.save_model(\"hallucination_xgb_model.json\")\n",
    "print(\"XGBoost model saved to hallucination_xgb_model.json\")\n",
    "\n",
    "# Save fitted feature pipeline\n",
    "with open(\"hallucination_feature_pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(feature_pipeline, f)\n",
    "print(\"Feature pipeline saved to hallucination_feature_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71480244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_mapped\n",
      "1    19720\n",
      "0    19720\n",
      "2    19719\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Re-map labels in your notebook for checking\n",
    "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
    "train_data['label_mapped'] = train_data['label'].map(label_mapping)\n",
    "\n",
    "# Now check the distribution\n",
    "print(train_data['label_mapped'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfbf17",
   "metadata": {},
   "source": [
    "### 1. Set OpenAI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5aae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai, os, json\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    print(\"Warning: OpenAI API key not found in environment variables\")\n",
    "    openai.api_key = input(\"Please enter your OpenAI API key: \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d11d4f",
   "metadata": {},
   "source": [
    "### 2. Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a34c9ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FEVER dataset...\n",
      "Dataset loaded with 145449 entries.\n",
      "Cleaning text data...\n",
      "Formatting evidence...\n",
      "\n",
      "Dataset Statistics:\n",
      "Total Claims: 135545\n",
      "label\n",
      " 1    73807\n",
      "-1    33567\n",
      " 0    28171\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Performing balanced sampling...\n",
      "\n",
      "Balanced Dataset Statistics:\n",
      "Total Claims: 84513\n",
      "label\n",
      "-1    28171\n",
      " 0    28171\n",
      " 1    28171\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"/Users/shubhamgaur/Desktop/NU/Sem4/IR/Project/Milestone2/train.jsonl\"\n",
    "df = process_fever_data(file_path, balanced_sampling=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b4b31",
   "metadata": {},
   "source": [
    "### 3. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e2f462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into train, validation, and test sets...\n",
      "Training set size: 59159\n",
      "Validation set size: 12677\n",
      "Test set size: 12677\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data, val_data, test_data = create_train_val_test_split(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da90f46",
   "metadata": {},
   "source": [
    "### 4. Add NLP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f7f3176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding NLP features...\n",
      "Calculating semantic similarities...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59159/59159 [15:01<00:00, 65.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12677/12677 [03:18<00:00, 63.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12677/12677 [03:08<00:00, 67.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating entity overlaps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59159/59159 [05:57<00:00, 165.58it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12677/12677 [01:16<00:00, 166.44it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12677/12677 [01:15<00:00, 167.25it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data, val_data, test_data = add_nlp_features(train_data, val_data, test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78759e5",
   "metadata": {},
   "source": [
    "### 5. Set Up RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de908cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up RAG system...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59159/59159 [00:01<00:00, 37453.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 59349 document chunks for RAG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/nfnk2vt17p57w20nk651d2vc0000gn/T/ipykernel_19802/2494486664.py:31: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG system setup complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vector_store = setup_rag_system(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d8904",
   "metadata": {},
   "source": [
    "### 6. Augment Test Data with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e641620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting test data with RAG-retrieved evidence...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12677/12677 [02:09<00:00, 98.01it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12677/12677 [03:09<00:00, 66.99it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12677/12677 [01:25<00:00, 147.87it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data = augment_evidence_with_rag(test_data, vector_store)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b32a50",
   "metadata": {},
   "source": [
    "### 7. Train ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d0dbe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ML model...\n",
      "Fitting model...\n",
      "Validation accuracy: 0.8154\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ml_model = train_ml_model(train_data, val_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33196d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "Fitting feature pipeline...\n",
      "Fitting XGBoost model with early stopping...\n",
      "[0]\tvalidation_0-mlogloss:1.05646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shubhamgaur/anaconda3/lib/python3.11/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalidation_0-mlogloss:1.01905\n",
      "[2]\tvalidation_0-mlogloss:0.98453\n",
      "[3]\tvalidation_0-mlogloss:0.95209\n",
      "[4]\tvalidation_0-mlogloss:0.92245\n",
      "[5]\tvalidation_0-mlogloss:0.89483\n",
      "[6]\tvalidation_0-mlogloss:0.86873\n",
      "[7]\tvalidation_0-mlogloss:0.84374\n",
      "[8]\tvalidation_0-mlogloss:0.82037\n",
      "[9]\tvalidation_0-mlogloss:0.79885\n",
      "[10]\tvalidation_0-mlogloss:0.77926\n",
      "[11]\tvalidation_0-mlogloss:0.76013\n",
      "[12]\tvalidation_0-mlogloss:0.74230\n",
      "[13]\tvalidation_0-mlogloss:0.72586\n",
      "[14]\tvalidation_0-mlogloss:0.71036\n",
      "[15]\tvalidation_0-mlogloss:0.69506\n",
      "[16]\tvalidation_0-mlogloss:0.68112\n",
      "[17]\tvalidation_0-mlogloss:0.66747\n",
      "[18]\tvalidation_0-mlogloss:0.65491\n",
      "[19]\tvalidation_0-mlogloss:0.64309\n",
      "[20]\tvalidation_0-mlogloss:0.63152\n",
      "[21]\tvalidation_0-mlogloss:0.62066\n",
      "[22]\tvalidation_0-mlogloss:0.61053\n",
      "[23]\tvalidation_0-mlogloss:0.60067\n",
      "[24]\tvalidation_0-mlogloss:0.59147\n",
      "[25]\tvalidation_0-mlogloss:0.58268\n",
      "[26]\tvalidation_0-mlogloss:0.57432\n",
      "[27]\tvalidation_0-mlogloss:0.56643\n",
      "[28]\tvalidation_0-mlogloss:0.55877\n",
      "[29]\tvalidation_0-mlogloss:0.55162\n",
      "[30]\tvalidation_0-mlogloss:0.54470\n",
      "[31]\tvalidation_0-mlogloss:0.53812\n",
      "[32]\tvalidation_0-mlogloss:0.53197\n",
      "[33]\tvalidation_0-mlogloss:0.52615\n",
      "[34]\tvalidation_0-mlogloss:0.52055\n",
      "[35]\tvalidation_0-mlogloss:0.51509\n",
      "[36]\tvalidation_0-mlogloss:0.50994\n",
      "[37]\tvalidation_0-mlogloss:0.50496\n",
      "[38]\tvalidation_0-mlogloss:0.50026\n",
      "[39]\tvalidation_0-mlogloss:0.49571\n",
      "[40]\tvalidation_0-mlogloss:0.49141\n",
      "[41]\tvalidation_0-mlogloss:0.48730\n",
      "[42]\tvalidation_0-mlogloss:0.48336\n",
      "[43]\tvalidation_0-mlogloss:0.47954\n",
      "[44]\tvalidation_0-mlogloss:0.47593\n",
      "[45]\tvalidation_0-mlogloss:0.47248\n",
      "[46]\tvalidation_0-mlogloss:0.46917\n",
      "[47]\tvalidation_0-mlogloss:0.46602\n",
      "[48]\tvalidation_0-mlogloss:0.46300\n",
      "[49]\tvalidation_0-mlogloss:0.46004\n",
      "[50]\tvalidation_0-mlogloss:0.45728\n",
      "[51]\tvalidation_0-mlogloss:0.45453\n",
      "[52]\tvalidation_0-mlogloss:0.45194\n",
      "[53]\tvalidation_0-mlogloss:0.44952\n",
      "[54]\tvalidation_0-mlogloss:0.44716\n",
      "[55]\tvalidation_0-mlogloss:0.44483\n",
      "[56]\tvalidation_0-mlogloss:0.44257\n",
      "[57]\tvalidation_0-mlogloss:0.44037\n",
      "[58]\tvalidation_0-mlogloss:0.43827\n",
      "[59]\tvalidation_0-mlogloss:0.43628\n",
      "[60]\tvalidation_0-mlogloss:0.43442\n",
      "[61]\tvalidation_0-mlogloss:0.43259\n",
      "[62]\tvalidation_0-mlogloss:0.43086\n",
      "[63]\tvalidation_0-mlogloss:0.42909\n",
      "[64]\tvalidation_0-mlogloss:0.42744\n",
      "[65]\tvalidation_0-mlogloss:0.42583\n",
      "[66]\tvalidation_0-mlogloss:0.42432\n",
      "[67]\tvalidation_0-mlogloss:0.42275\n",
      "[68]\tvalidation_0-mlogloss:0.42115\n",
      "[69]\tvalidation_0-mlogloss:0.41967\n",
      "[70]\tvalidation_0-mlogloss:0.41831\n",
      "[71]\tvalidation_0-mlogloss:0.41700\n",
      "[72]\tvalidation_0-mlogloss:0.41569\n",
      "[73]\tvalidation_0-mlogloss:0.41447\n",
      "[74]\tvalidation_0-mlogloss:0.41324\n",
      "[75]\tvalidation_0-mlogloss:0.41212\n",
      "[76]\tvalidation_0-mlogloss:0.41093\n",
      "[77]\tvalidation_0-mlogloss:0.40992\n",
      "[78]\tvalidation_0-mlogloss:0.40887\n",
      "[79]\tvalidation_0-mlogloss:0.40790\n",
      "[80]\tvalidation_0-mlogloss:0.40674\n",
      "[81]\tvalidation_0-mlogloss:0.40580\n",
      "[82]\tvalidation_0-mlogloss:0.40489\n",
      "[83]\tvalidation_0-mlogloss:0.40393\n",
      "[84]\tvalidation_0-mlogloss:0.40304\n",
      "[85]\tvalidation_0-mlogloss:0.40212\n",
      "[86]\tvalidation_0-mlogloss:0.40126\n",
      "[87]\tvalidation_0-mlogloss:0.40037\n",
      "[88]\tvalidation_0-mlogloss:0.39957\n",
      "[89]\tvalidation_0-mlogloss:0.39884\n",
      "[90]\tvalidation_0-mlogloss:0.39813\n",
      "[91]\tvalidation_0-mlogloss:0.39744\n",
      "[92]\tvalidation_0-mlogloss:0.39676\n",
      "[93]\tvalidation_0-mlogloss:0.39608\n",
      "[94]\tvalidation_0-mlogloss:0.39544\n",
      "[95]\tvalidation_0-mlogloss:0.39478\n",
      "[96]\tvalidation_0-mlogloss:0.39411\n",
      "[97]\tvalidation_0-mlogloss:0.39346\n",
      "[98]\tvalidation_0-mlogloss:0.39284\n",
      "[99]\tvalidation_0-mlogloss:0.39216\n",
      "[100]\tvalidation_0-mlogloss:0.39142\n",
      "[101]\tvalidation_0-mlogloss:0.39088\n",
      "[102]\tvalidation_0-mlogloss:0.39027\n",
      "[103]\tvalidation_0-mlogloss:0.38961\n",
      "[104]\tvalidation_0-mlogloss:0.38904\n",
      "[105]\tvalidation_0-mlogloss:0.38846\n",
      "[106]\tvalidation_0-mlogloss:0.38801\n",
      "[107]\tvalidation_0-mlogloss:0.38747\n",
      "[108]\tvalidation_0-mlogloss:0.38704\n",
      "[109]\tvalidation_0-mlogloss:0.38649\n",
      "[110]\tvalidation_0-mlogloss:0.38601\n",
      "[111]\tvalidation_0-mlogloss:0.38550\n",
      "[112]\tvalidation_0-mlogloss:0.38500\n",
      "[113]\tvalidation_0-mlogloss:0.38457\n",
      "[114]\tvalidation_0-mlogloss:0.38417\n",
      "[115]\tvalidation_0-mlogloss:0.38375\n",
      "[116]\tvalidation_0-mlogloss:0.38335\n",
      "[117]\tvalidation_0-mlogloss:0.38292\n",
      "[118]\tvalidation_0-mlogloss:0.38242\n",
      "[119]\tvalidation_0-mlogloss:0.38203\n",
      "[120]\tvalidation_0-mlogloss:0.38169\n",
      "[121]\tvalidation_0-mlogloss:0.38131\n",
      "[122]\tvalidation_0-mlogloss:0.38095\n",
      "[123]\tvalidation_0-mlogloss:0.38061\n",
      "[124]\tvalidation_0-mlogloss:0.38026\n",
      "[125]\tvalidation_0-mlogloss:0.37994\n",
      "[126]\tvalidation_0-mlogloss:0.37959\n",
      "[127]\tvalidation_0-mlogloss:0.37928\n",
      "[128]\tvalidation_0-mlogloss:0.37897\n",
      "[129]\tvalidation_0-mlogloss:0.37865\n",
      "[130]\tvalidation_0-mlogloss:0.37832\n",
      "[131]\tvalidation_0-mlogloss:0.37800\n",
      "[132]\tvalidation_0-mlogloss:0.37766\n",
      "[133]\tvalidation_0-mlogloss:0.37734\n",
      "[134]\tvalidation_0-mlogloss:0.37704\n",
      "[135]\tvalidation_0-mlogloss:0.37668\n",
      "[136]\tvalidation_0-mlogloss:0.37635\n",
      "[137]\tvalidation_0-mlogloss:0.37610\n",
      "[138]\tvalidation_0-mlogloss:0.37577\n",
      "[139]\tvalidation_0-mlogloss:0.37553\n",
      "[140]\tvalidation_0-mlogloss:0.37519\n",
      "[141]\tvalidation_0-mlogloss:0.37488\n",
      "[142]\tvalidation_0-mlogloss:0.37466\n",
      "[143]\tvalidation_0-mlogloss:0.37433\n",
      "[144]\tvalidation_0-mlogloss:0.37405\n",
      "[145]\tvalidation_0-mlogloss:0.37374\n",
      "[146]\tvalidation_0-mlogloss:0.37351\n",
      "[147]\tvalidation_0-mlogloss:0.37323\n",
      "[148]\tvalidation_0-mlogloss:0.37304\n",
      "[149]\tvalidation_0-mlogloss:0.37279\n",
      "[150]\tvalidation_0-mlogloss:0.37258\n",
      "[151]\tvalidation_0-mlogloss:0.37234\n",
      "[152]\tvalidation_0-mlogloss:0.37210\n",
      "[153]\tvalidation_0-mlogloss:0.37189\n",
      "[154]\tvalidation_0-mlogloss:0.37166\n",
      "[155]\tvalidation_0-mlogloss:0.37144\n",
      "[156]\tvalidation_0-mlogloss:0.37121\n",
      "[157]\tvalidation_0-mlogloss:0.37104\n",
      "[158]\tvalidation_0-mlogloss:0.37085\n",
      "[159]\tvalidation_0-mlogloss:0.37067\n",
      "[160]\tvalidation_0-mlogloss:0.37042\n",
      "[161]\tvalidation_0-mlogloss:0.37023\n",
      "[162]\tvalidation_0-mlogloss:0.37000\n",
      "[163]\tvalidation_0-mlogloss:0.36983\n",
      "[164]\tvalidation_0-mlogloss:0.36963\n",
      "[165]\tvalidation_0-mlogloss:0.36950\n",
      "[166]\tvalidation_0-mlogloss:0.36928\n",
      "[167]\tvalidation_0-mlogloss:0.36906\n",
      "[168]\tvalidation_0-mlogloss:0.36878\n",
      "[169]\tvalidation_0-mlogloss:0.36860\n",
      "[170]\tvalidation_0-mlogloss:0.36835\n",
      "[171]\tvalidation_0-mlogloss:0.36818\n",
      "[172]\tvalidation_0-mlogloss:0.36803\n",
      "[173]\tvalidation_0-mlogloss:0.36789\n",
      "[174]\tvalidation_0-mlogloss:0.36773\n",
      "[175]\tvalidation_0-mlogloss:0.36752\n",
      "[176]\tvalidation_0-mlogloss:0.36735\n",
      "[177]\tvalidation_0-mlogloss:0.36723\n",
      "[178]\tvalidation_0-mlogloss:0.36711\n",
      "[179]\tvalidation_0-mlogloss:0.36689\n",
      "[180]\tvalidation_0-mlogloss:0.36673\n",
      "[181]\tvalidation_0-mlogloss:0.36656\n",
      "[182]\tvalidation_0-mlogloss:0.36639\n",
      "[183]\tvalidation_0-mlogloss:0.36623\n",
      "[184]\tvalidation_0-mlogloss:0.36604\n",
      "[185]\tvalidation_0-mlogloss:0.36593\n",
      "[186]\tvalidation_0-mlogloss:0.36576\n",
      "[187]\tvalidation_0-mlogloss:0.36559\n",
      "[188]\tvalidation_0-mlogloss:0.36533\n",
      "[189]\tvalidation_0-mlogloss:0.36520\n",
      "[190]\tvalidation_0-mlogloss:0.36506\n",
      "[191]\tvalidation_0-mlogloss:0.36494\n",
      "[192]\tvalidation_0-mlogloss:0.36479\n",
      "[193]\tvalidation_0-mlogloss:0.36468\n",
      "[194]\tvalidation_0-mlogloss:0.36452\n",
      "[195]\tvalidation_0-mlogloss:0.36436\n",
      "[196]\tvalidation_0-mlogloss:0.36418\n",
      "[197]\tvalidation_0-mlogloss:0.36401\n",
      "[198]\tvalidation_0-mlogloss:0.36389\n",
      "[199]\tvalidation_0-mlogloss:0.36379\n",
      "[200]\tvalidation_0-mlogloss:0.36356\n",
      "[201]\tvalidation_0-mlogloss:0.36344\n",
      "[202]\tvalidation_0-mlogloss:0.36334\n",
      "[203]\tvalidation_0-mlogloss:0.36320\n",
      "[204]\tvalidation_0-mlogloss:0.36312\n",
      "[205]\tvalidation_0-mlogloss:0.36300\n",
      "[206]\tvalidation_0-mlogloss:0.36290\n",
      "[207]\tvalidation_0-mlogloss:0.36272\n",
      "[208]\tvalidation_0-mlogloss:0.36259\n",
      "[209]\tvalidation_0-mlogloss:0.36250\n",
      "[210]\tvalidation_0-mlogloss:0.36234\n",
      "[211]\tvalidation_0-mlogloss:0.36225\n",
      "[212]\tvalidation_0-mlogloss:0.36210\n",
      "[213]\tvalidation_0-mlogloss:0.36199\n",
      "[214]\tvalidation_0-mlogloss:0.36186\n",
      "[215]\tvalidation_0-mlogloss:0.36175\n",
      "[216]\tvalidation_0-mlogloss:0.36164\n",
      "[217]\tvalidation_0-mlogloss:0.36154\n",
      "[218]\tvalidation_0-mlogloss:0.36141\n",
      "[219]\tvalidation_0-mlogloss:0.36130\n",
      "[220]\tvalidation_0-mlogloss:0.36121\n",
      "[221]\tvalidation_0-mlogloss:0.36111\n",
      "[222]\tvalidation_0-mlogloss:0.36103\n",
      "[223]\tvalidation_0-mlogloss:0.36091\n",
      "[224]\tvalidation_0-mlogloss:0.36077\n",
      "[225]\tvalidation_0-mlogloss:0.36068\n",
      "[226]\tvalidation_0-mlogloss:0.36057\n",
      "[227]\tvalidation_0-mlogloss:0.36047\n",
      "[228]\tvalidation_0-mlogloss:0.36039\n",
      "[229]\tvalidation_0-mlogloss:0.36030\n",
      "[230]\tvalidation_0-mlogloss:0.36017\n",
      "[231]\tvalidation_0-mlogloss:0.36008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[232]\tvalidation_0-mlogloss:0.35999\n",
      "[233]\tvalidation_0-mlogloss:0.35990\n",
      "[234]\tvalidation_0-mlogloss:0.35979\n",
      "[235]\tvalidation_0-mlogloss:0.35972\n",
      "[236]\tvalidation_0-mlogloss:0.35968\n",
      "[237]\tvalidation_0-mlogloss:0.35962\n",
      "[238]\tvalidation_0-mlogloss:0.35956\n",
      "[239]\tvalidation_0-mlogloss:0.35949\n",
      "[240]\tvalidation_0-mlogloss:0.35943\n",
      "[241]\tvalidation_0-mlogloss:0.35932\n",
      "[242]\tvalidation_0-mlogloss:0.35922\n",
      "[243]\tvalidation_0-mlogloss:0.35911\n",
      "[244]\tvalidation_0-mlogloss:0.35907\n",
      "[245]\tvalidation_0-mlogloss:0.35902\n",
      "[246]\tvalidation_0-mlogloss:0.35892\n",
      "[247]\tvalidation_0-mlogloss:0.35880\n",
      "[248]\tvalidation_0-mlogloss:0.35872\n",
      "[249]\tvalidation_0-mlogloss:0.35862\n",
      "[250]\tvalidation_0-mlogloss:0.35855\n",
      "[251]\tvalidation_0-mlogloss:0.35847\n",
      "[252]\tvalidation_0-mlogloss:0.35839\n",
      "[253]\tvalidation_0-mlogloss:0.35825\n",
      "[254]\tvalidation_0-mlogloss:0.35817\n",
      "[255]\tvalidation_0-mlogloss:0.35806\n",
      "[256]\tvalidation_0-mlogloss:0.35796\n",
      "[257]\tvalidation_0-mlogloss:0.35786\n",
      "[258]\tvalidation_0-mlogloss:0.35780\n",
      "[259]\tvalidation_0-mlogloss:0.35772\n",
      "[260]\tvalidation_0-mlogloss:0.35764\n",
      "[261]\tvalidation_0-mlogloss:0.35757\n",
      "[262]\tvalidation_0-mlogloss:0.35752\n",
      "[263]\tvalidation_0-mlogloss:0.35746\n",
      "[264]\tvalidation_0-mlogloss:0.35735\n",
      "[265]\tvalidation_0-mlogloss:0.35725\n",
      "[266]\tvalidation_0-mlogloss:0.35717\n",
      "[267]\tvalidation_0-mlogloss:0.35705\n",
      "[268]\tvalidation_0-mlogloss:0.35697\n",
      "[269]\tvalidation_0-mlogloss:0.35688\n",
      "[270]\tvalidation_0-mlogloss:0.35675\n",
      "[271]\tvalidation_0-mlogloss:0.35664\n",
      "[272]\tvalidation_0-mlogloss:0.35654\n",
      "[273]\tvalidation_0-mlogloss:0.35642\n",
      "[274]\tvalidation_0-mlogloss:0.35630\n",
      "[275]\tvalidation_0-mlogloss:0.35622\n",
      "[276]\tvalidation_0-mlogloss:0.35619\n",
      "[277]\tvalidation_0-mlogloss:0.35611\n",
      "[278]\tvalidation_0-mlogloss:0.35599\n",
      "[279]\tvalidation_0-mlogloss:0.35588\n",
      "[280]\tvalidation_0-mlogloss:0.35572\n",
      "[281]\tvalidation_0-mlogloss:0.35569\n",
      "[282]\tvalidation_0-mlogloss:0.35563\n",
      "[283]\tvalidation_0-mlogloss:0.35559\n",
      "[284]\tvalidation_0-mlogloss:0.35553\n",
      "[285]\tvalidation_0-mlogloss:0.35547\n",
      "[286]\tvalidation_0-mlogloss:0.35539\n",
      "[287]\tvalidation_0-mlogloss:0.35533\n",
      "[288]\tvalidation_0-mlogloss:0.35524\n",
      "[289]\tvalidation_0-mlogloss:0.35518\n",
      "[290]\tvalidation_0-mlogloss:0.35508\n",
      "[291]\tvalidation_0-mlogloss:0.35504\n",
      "[292]\tvalidation_0-mlogloss:0.35494\n",
      "[293]\tvalidation_0-mlogloss:0.35490\n",
      "[294]\tvalidation_0-mlogloss:0.35484\n",
      "[295]\tvalidation_0-mlogloss:0.35478\n",
      "[296]\tvalidation_0-mlogloss:0.35472\n",
      "[297]\tvalidation_0-mlogloss:0.35468\n",
      "[298]\tvalidation_0-mlogloss:0.35462\n",
      "[299]\tvalidation_0-mlogloss:0.35454\n",
      "[300]\tvalidation_0-mlogloss:0.35451\n",
      "[301]\tvalidation_0-mlogloss:0.35442\n",
      "[302]\tvalidation_0-mlogloss:0.35436\n",
      "[303]\tvalidation_0-mlogloss:0.35431\n",
      "[304]\tvalidation_0-mlogloss:0.35423\n",
      "[305]\tvalidation_0-mlogloss:0.35417\n",
      "[306]\tvalidation_0-mlogloss:0.35410\n",
      "[307]\tvalidation_0-mlogloss:0.35403\n",
      "[308]\tvalidation_0-mlogloss:0.35395\n",
      "[309]\tvalidation_0-mlogloss:0.35389\n",
      "[310]\tvalidation_0-mlogloss:0.35381\n",
      "[311]\tvalidation_0-mlogloss:0.35375\n",
      "[312]\tvalidation_0-mlogloss:0.35364\n",
      "[313]\tvalidation_0-mlogloss:0.35358\n",
      "[314]\tvalidation_0-mlogloss:0.35354\n",
      "[315]\tvalidation_0-mlogloss:0.35352\n",
      "[316]\tvalidation_0-mlogloss:0.35342\n",
      "[317]\tvalidation_0-mlogloss:0.35340\n",
      "[318]\tvalidation_0-mlogloss:0.35331\n",
      "[319]\tvalidation_0-mlogloss:0.35323\n",
      "[320]\tvalidation_0-mlogloss:0.35317\n",
      "[321]\tvalidation_0-mlogloss:0.35310\n",
      "[322]\tvalidation_0-mlogloss:0.35298\n",
      "[323]\tvalidation_0-mlogloss:0.35288\n",
      "[324]\tvalidation_0-mlogloss:0.35279\n",
      "[325]\tvalidation_0-mlogloss:0.35272\n",
      "[326]\tvalidation_0-mlogloss:0.35266\n",
      "[327]\tvalidation_0-mlogloss:0.35261\n",
      "[328]\tvalidation_0-mlogloss:0.35252\n",
      "[329]\tvalidation_0-mlogloss:0.35244\n",
      "[330]\tvalidation_0-mlogloss:0.35242\n",
      "[331]\tvalidation_0-mlogloss:0.35238\n",
      "[332]\tvalidation_0-mlogloss:0.35231\n",
      "[333]\tvalidation_0-mlogloss:0.35226\n",
      "[334]\tvalidation_0-mlogloss:0.35220\n",
      "[335]\tvalidation_0-mlogloss:0.35214\n",
      "[336]\tvalidation_0-mlogloss:0.35212\n",
      "[337]\tvalidation_0-mlogloss:0.35205\n",
      "[338]\tvalidation_0-mlogloss:0.35202\n",
      "[339]\tvalidation_0-mlogloss:0.35196\n",
      "[340]\tvalidation_0-mlogloss:0.35189\n",
      "[341]\tvalidation_0-mlogloss:0.35184\n",
      "[342]\tvalidation_0-mlogloss:0.35175\n",
      "[343]\tvalidation_0-mlogloss:0.35169\n",
      "[344]\tvalidation_0-mlogloss:0.35165\n",
      "[345]\tvalidation_0-mlogloss:0.35163\n",
      "[346]\tvalidation_0-mlogloss:0.35156\n",
      "[347]\tvalidation_0-mlogloss:0.35153\n",
      "[348]\tvalidation_0-mlogloss:0.35146\n",
      "[349]\tvalidation_0-mlogloss:0.35140\n",
      "[350]\tvalidation_0-mlogloss:0.35134\n",
      "[351]\tvalidation_0-mlogloss:0.35131\n",
      "[352]\tvalidation_0-mlogloss:0.35125\n",
      "[353]\tvalidation_0-mlogloss:0.35122\n",
      "[354]\tvalidation_0-mlogloss:0.35114\n",
      "[355]\tvalidation_0-mlogloss:0.35112\n",
      "[356]\tvalidation_0-mlogloss:0.35106\n",
      "[357]\tvalidation_0-mlogloss:0.35099\n",
      "[358]\tvalidation_0-mlogloss:0.35092\n",
      "[359]\tvalidation_0-mlogloss:0.35086\n",
      "[360]\tvalidation_0-mlogloss:0.35083\n",
      "[361]\tvalidation_0-mlogloss:0.35076\n",
      "[362]\tvalidation_0-mlogloss:0.35070\n",
      "[363]\tvalidation_0-mlogloss:0.35062\n",
      "[364]\tvalidation_0-mlogloss:0.35061\n",
      "[365]\tvalidation_0-mlogloss:0.35059\n",
      "[366]\tvalidation_0-mlogloss:0.35053\n",
      "[367]\tvalidation_0-mlogloss:0.35046\n",
      "[368]\tvalidation_0-mlogloss:0.35044\n",
      "[369]\tvalidation_0-mlogloss:0.35040\n",
      "[370]\tvalidation_0-mlogloss:0.35038\n",
      "[371]\tvalidation_0-mlogloss:0.35031\n",
      "[372]\tvalidation_0-mlogloss:0.35028\n",
      "[373]\tvalidation_0-mlogloss:0.35020\n",
      "[374]\tvalidation_0-mlogloss:0.35015\n",
      "[375]\tvalidation_0-mlogloss:0.35012\n",
      "[376]\tvalidation_0-mlogloss:0.35007\n",
      "[377]\tvalidation_0-mlogloss:0.35004\n",
      "[378]\tvalidation_0-mlogloss:0.34997\n",
      "[379]\tvalidation_0-mlogloss:0.34991\n",
      "[380]\tvalidation_0-mlogloss:0.34987\n",
      "[381]\tvalidation_0-mlogloss:0.34986\n",
      "[382]\tvalidation_0-mlogloss:0.34983\n",
      "[383]\tvalidation_0-mlogloss:0.34977\n",
      "[384]\tvalidation_0-mlogloss:0.34975\n",
      "[385]\tvalidation_0-mlogloss:0.34970\n",
      "[386]\tvalidation_0-mlogloss:0.34967\n",
      "[387]\tvalidation_0-mlogloss:0.34961\n",
      "[388]\tvalidation_0-mlogloss:0.34958\n",
      "[389]\tvalidation_0-mlogloss:0.34953\n",
      "[390]\tvalidation_0-mlogloss:0.34947\n",
      "[391]\tvalidation_0-mlogloss:0.34936\n",
      "[392]\tvalidation_0-mlogloss:0.34928\n",
      "[393]\tvalidation_0-mlogloss:0.34925\n",
      "[394]\tvalidation_0-mlogloss:0.34921\n",
      "[395]\tvalidation_0-mlogloss:0.34919\n",
      "[396]\tvalidation_0-mlogloss:0.34918\n",
      "[397]\tvalidation_0-mlogloss:0.34915\n",
      "[398]\tvalidation_0-mlogloss:0.34912\n",
      "[399]\tvalidation_0-mlogloss:0.34907\n",
      "[400]\tvalidation_0-mlogloss:0.34905\n",
      "[401]\tvalidation_0-mlogloss:0.34900\n",
      "[402]\tvalidation_0-mlogloss:0.34898\n",
      "[403]\tvalidation_0-mlogloss:0.34896\n",
      "[404]\tvalidation_0-mlogloss:0.34891\n",
      "[405]\tvalidation_0-mlogloss:0.34889\n",
      "[406]\tvalidation_0-mlogloss:0.34881\n",
      "[407]\tvalidation_0-mlogloss:0.34874\n",
      "[408]\tvalidation_0-mlogloss:0.34866\n",
      "[409]\tvalidation_0-mlogloss:0.34864\n",
      "[410]\tvalidation_0-mlogloss:0.34861\n",
      "[411]\tvalidation_0-mlogloss:0.34856\n",
      "[412]\tvalidation_0-mlogloss:0.34853\n",
      "[413]\tvalidation_0-mlogloss:0.34847\n",
      "[414]\tvalidation_0-mlogloss:0.34840\n",
      "[415]\tvalidation_0-mlogloss:0.34833\n",
      "[416]\tvalidation_0-mlogloss:0.34824\n",
      "[417]\tvalidation_0-mlogloss:0.34821\n",
      "[418]\tvalidation_0-mlogloss:0.34820\n",
      "[419]\tvalidation_0-mlogloss:0.34820\n",
      "[420]\tvalidation_0-mlogloss:0.34818\n",
      "[421]\tvalidation_0-mlogloss:0.34814\n",
      "[422]\tvalidation_0-mlogloss:0.34810\n",
      "[423]\tvalidation_0-mlogloss:0.34807\n",
      "[424]\tvalidation_0-mlogloss:0.34806\n",
      "[425]\tvalidation_0-mlogloss:0.34801\n",
      "[426]\tvalidation_0-mlogloss:0.34798\n",
      "[427]\tvalidation_0-mlogloss:0.34794\n",
      "[428]\tvalidation_0-mlogloss:0.34790\n",
      "[429]\tvalidation_0-mlogloss:0.34785\n",
      "[430]\tvalidation_0-mlogloss:0.34780\n",
      "[431]\tvalidation_0-mlogloss:0.34777\n",
      "[432]\tvalidation_0-mlogloss:0.34776\n",
      "[433]\tvalidation_0-mlogloss:0.34774\n",
      "[434]\tvalidation_0-mlogloss:0.34772\n",
      "[435]\tvalidation_0-mlogloss:0.34771\n",
      "[436]\tvalidation_0-mlogloss:0.34772\n",
      "[437]\tvalidation_0-mlogloss:0.34769\n",
      "[438]\tvalidation_0-mlogloss:0.34765\n",
      "[439]\tvalidation_0-mlogloss:0.34761\n",
      "[440]\tvalidation_0-mlogloss:0.34753\n",
      "[441]\tvalidation_0-mlogloss:0.34749\n",
      "[442]\tvalidation_0-mlogloss:0.34747\n",
      "[443]\tvalidation_0-mlogloss:0.34747\n",
      "[444]\tvalidation_0-mlogloss:0.34743\n",
      "[445]\tvalidation_0-mlogloss:0.34741\n",
      "[446]\tvalidation_0-mlogloss:0.34737\n",
      "[447]\tvalidation_0-mlogloss:0.34735\n",
      "[448]\tvalidation_0-mlogloss:0.34727\n",
      "[449]\tvalidation_0-mlogloss:0.34728\n",
      "[450]\tvalidation_0-mlogloss:0.34723\n",
      "[451]\tvalidation_0-mlogloss:0.34716\n",
      "[452]\tvalidation_0-mlogloss:0.34717\n",
      "[453]\tvalidation_0-mlogloss:0.34714\n",
      "[454]\tvalidation_0-mlogloss:0.34710\n",
      "[455]\tvalidation_0-mlogloss:0.34704\n",
      "[456]\tvalidation_0-mlogloss:0.34702\n",
      "[457]\tvalidation_0-mlogloss:0.34700\n",
      "[458]\tvalidation_0-mlogloss:0.34697\n",
      "[459]\tvalidation_0-mlogloss:0.34693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[460]\tvalidation_0-mlogloss:0.34693\n",
      "[461]\tvalidation_0-mlogloss:0.34691\n",
      "[462]\tvalidation_0-mlogloss:0.34689\n",
      "[463]\tvalidation_0-mlogloss:0.34689\n",
      "[464]\tvalidation_0-mlogloss:0.34687\n",
      "[465]\tvalidation_0-mlogloss:0.34681\n",
      "[466]\tvalidation_0-mlogloss:0.34678\n",
      "[467]\tvalidation_0-mlogloss:0.34672\n",
      "[468]\tvalidation_0-mlogloss:0.34669\n",
      "[469]\tvalidation_0-mlogloss:0.34664\n",
      "[470]\tvalidation_0-mlogloss:0.34661\n",
      "[471]\tvalidation_0-mlogloss:0.34658\n",
      "[472]\tvalidation_0-mlogloss:0.34652\n",
      "[473]\tvalidation_0-mlogloss:0.34650\n",
      "[474]\tvalidation_0-mlogloss:0.34652\n",
      "[475]\tvalidation_0-mlogloss:0.34640\n",
      "[476]\tvalidation_0-mlogloss:0.34640\n",
      "[477]\tvalidation_0-mlogloss:0.34638\n",
      "[478]\tvalidation_0-mlogloss:0.34633\n",
      "[479]\tvalidation_0-mlogloss:0.34627\n",
      "[480]\tvalidation_0-mlogloss:0.34625\n",
      "[481]\tvalidation_0-mlogloss:0.34620\n",
      "[482]\tvalidation_0-mlogloss:0.34618\n",
      "[483]\tvalidation_0-mlogloss:0.34617\n",
      "[484]\tvalidation_0-mlogloss:0.34608\n",
      "[485]\tvalidation_0-mlogloss:0.34606\n",
      "[486]\tvalidation_0-mlogloss:0.34602\n",
      "[487]\tvalidation_0-mlogloss:0.34600\n",
      "[488]\tvalidation_0-mlogloss:0.34598\n",
      "[489]\tvalidation_0-mlogloss:0.34595\n",
      "[490]\tvalidation_0-mlogloss:0.34592\n",
      "[491]\tvalidation_0-mlogloss:0.34588\n",
      "[492]\tvalidation_0-mlogloss:0.34589\n",
      "[493]\tvalidation_0-mlogloss:0.34583\n",
      "[494]\tvalidation_0-mlogloss:0.34581\n",
      "[495]\tvalidation_0-mlogloss:0.34576\n",
      "[496]\tvalidation_0-mlogloss:0.34573\n",
      "[497]\tvalidation_0-mlogloss:0.34569\n",
      "[498]\tvalidation_0-mlogloss:0.34568\n",
      "[499]\tvalidation_0-mlogloss:0.34566\n",
      "[500]\tvalidation_0-mlogloss:0.34564\n",
      "[501]\tvalidation_0-mlogloss:0.34562\n",
      "[502]\tvalidation_0-mlogloss:0.34563\n",
      "[503]\tvalidation_0-mlogloss:0.34563\n",
      "[504]\tvalidation_0-mlogloss:0.34563\n",
      "[505]\tvalidation_0-mlogloss:0.34559\n",
      "[506]\tvalidation_0-mlogloss:0.34556\n",
      "[507]\tvalidation_0-mlogloss:0.34551\n",
      "[508]\tvalidation_0-mlogloss:0.34552\n",
      "[509]\tvalidation_0-mlogloss:0.34546\n",
      "[510]\tvalidation_0-mlogloss:0.34550\n",
      "[511]\tvalidation_0-mlogloss:0.34548\n",
      "[512]\tvalidation_0-mlogloss:0.34545\n",
      "[513]\tvalidation_0-mlogloss:0.34540\n",
      "[514]\tvalidation_0-mlogloss:0.34533\n",
      "[515]\tvalidation_0-mlogloss:0.34531\n",
      "[516]\tvalidation_0-mlogloss:0.34528\n",
      "[517]\tvalidation_0-mlogloss:0.34524\n",
      "[518]\tvalidation_0-mlogloss:0.34522\n",
      "[519]\tvalidation_0-mlogloss:0.34521\n",
      "[520]\tvalidation_0-mlogloss:0.34519\n",
      "[521]\tvalidation_0-mlogloss:0.34512\n",
      "[522]\tvalidation_0-mlogloss:0.34510\n",
      "[523]\tvalidation_0-mlogloss:0.34509\n",
      "[524]\tvalidation_0-mlogloss:0.34506\n",
      "[525]\tvalidation_0-mlogloss:0.34500\n",
      "[526]\tvalidation_0-mlogloss:0.34498\n",
      "[527]\tvalidation_0-mlogloss:0.34493\n",
      "[528]\tvalidation_0-mlogloss:0.34493\n",
      "[529]\tvalidation_0-mlogloss:0.34493\n",
      "[530]\tvalidation_0-mlogloss:0.34492\n",
      "[531]\tvalidation_0-mlogloss:0.34493\n",
      "[532]\tvalidation_0-mlogloss:0.34490\n",
      "[533]\tvalidation_0-mlogloss:0.34483\n",
      "[534]\tvalidation_0-mlogloss:0.34484\n",
      "[535]\tvalidation_0-mlogloss:0.34483\n",
      "[536]\tvalidation_0-mlogloss:0.34478\n",
      "[537]\tvalidation_0-mlogloss:0.34472\n",
      "[538]\tvalidation_0-mlogloss:0.34470\n",
      "[539]\tvalidation_0-mlogloss:0.34467\n",
      "[540]\tvalidation_0-mlogloss:0.34469\n",
      "[541]\tvalidation_0-mlogloss:0.34469\n",
      "[542]\tvalidation_0-mlogloss:0.34468\n",
      "[543]\tvalidation_0-mlogloss:0.34467\n",
      "[544]\tvalidation_0-mlogloss:0.34468\n",
      "[545]\tvalidation_0-mlogloss:0.34467\n",
      "[546]\tvalidation_0-mlogloss:0.34464\n",
      "[547]\tvalidation_0-mlogloss:0.34461\n",
      "[548]\tvalidation_0-mlogloss:0.34460\n",
      "[549]\tvalidation_0-mlogloss:0.34457\n",
      "[550]\tvalidation_0-mlogloss:0.34456\n",
      "[551]\tvalidation_0-mlogloss:0.34454\n",
      "[552]\tvalidation_0-mlogloss:0.34451\n",
      "[553]\tvalidation_0-mlogloss:0.34449\n",
      "[554]\tvalidation_0-mlogloss:0.34449\n",
      "[555]\tvalidation_0-mlogloss:0.34448\n",
      "[556]\tvalidation_0-mlogloss:0.34440\n",
      "[557]\tvalidation_0-mlogloss:0.34438\n",
      "[558]\tvalidation_0-mlogloss:0.34435\n",
      "[559]\tvalidation_0-mlogloss:0.34435\n",
      "[560]\tvalidation_0-mlogloss:0.34435\n",
      "[561]\tvalidation_0-mlogloss:0.34430\n",
      "[562]\tvalidation_0-mlogloss:0.34428\n",
      "[563]\tvalidation_0-mlogloss:0.34426\n",
      "[564]\tvalidation_0-mlogloss:0.34425\n",
      "[565]\tvalidation_0-mlogloss:0.34422\n",
      "[566]\tvalidation_0-mlogloss:0.34418\n",
      "[567]\tvalidation_0-mlogloss:0.34413\n",
      "[568]\tvalidation_0-mlogloss:0.34412\n",
      "[569]\tvalidation_0-mlogloss:0.34411\n",
      "[570]\tvalidation_0-mlogloss:0.34409\n",
      "[571]\tvalidation_0-mlogloss:0.34409\n",
      "[572]\tvalidation_0-mlogloss:0.34405\n",
      "[573]\tvalidation_0-mlogloss:0.34405\n",
      "[574]\tvalidation_0-mlogloss:0.34404\n",
      "[575]\tvalidation_0-mlogloss:0.34403\n",
      "[576]\tvalidation_0-mlogloss:0.34403\n",
      "[577]\tvalidation_0-mlogloss:0.34400\n",
      "[578]\tvalidation_0-mlogloss:0.34399\n",
      "[579]\tvalidation_0-mlogloss:0.34396\n",
      "[580]\tvalidation_0-mlogloss:0.34395\n",
      "[581]\tvalidation_0-mlogloss:0.34397\n",
      "[582]\tvalidation_0-mlogloss:0.34394\n",
      "[583]\tvalidation_0-mlogloss:0.34391\n",
      "[584]\tvalidation_0-mlogloss:0.34389\n",
      "[585]\tvalidation_0-mlogloss:0.34386\n",
      "[586]\tvalidation_0-mlogloss:0.34384\n",
      "[587]\tvalidation_0-mlogloss:0.34381\n",
      "[588]\tvalidation_0-mlogloss:0.34380\n",
      "[589]\tvalidation_0-mlogloss:0.34380\n",
      "[590]\tvalidation_0-mlogloss:0.34377\n",
      "[591]\tvalidation_0-mlogloss:0.34376\n",
      "[592]\tvalidation_0-mlogloss:0.34374\n",
      "[593]\tvalidation_0-mlogloss:0.34370\n",
      "[594]\tvalidation_0-mlogloss:0.34370\n",
      "[595]\tvalidation_0-mlogloss:0.34368\n",
      "[596]\tvalidation_0-mlogloss:0.34365\n",
      "[597]\tvalidation_0-mlogloss:0.34360\n",
      "[598]\tvalidation_0-mlogloss:0.34358\n",
      "[599]\tvalidation_0-mlogloss:0.34355\n",
      "[600]\tvalidation_0-mlogloss:0.34356\n",
      "[601]\tvalidation_0-mlogloss:0.34351\n",
      "[602]\tvalidation_0-mlogloss:0.34353\n",
      "[603]\tvalidation_0-mlogloss:0.34350\n",
      "[604]\tvalidation_0-mlogloss:0.34350\n",
      "[605]\tvalidation_0-mlogloss:0.34345\n",
      "[606]\tvalidation_0-mlogloss:0.34343\n",
      "[607]\tvalidation_0-mlogloss:0.34343\n",
      "[608]\tvalidation_0-mlogloss:0.34346\n",
      "[609]\tvalidation_0-mlogloss:0.34345\n",
      "[610]\tvalidation_0-mlogloss:0.34344\n",
      "[611]\tvalidation_0-mlogloss:0.34342\n",
      "[612]\tvalidation_0-mlogloss:0.34340\n",
      "[613]\tvalidation_0-mlogloss:0.34341\n",
      "[614]\tvalidation_0-mlogloss:0.34341\n",
      "[615]\tvalidation_0-mlogloss:0.34341\n",
      "[616]\tvalidation_0-mlogloss:0.34334\n",
      "[617]\tvalidation_0-mlogloss:0.34329\n",
      "[618]\tvalidation_0-mlogloss:0.34323\n",
      "[619]\tvalidation_0-mlogloss:0.34322\n",
      "[620]\tvalidation_0-mlogloss:0.34321\n",
      "[621]\tvalidation_0-mlogloss:0.34320\n",
      "[622]\tvalidation_0-mlogloss:0.34316\n",
      "[623]\tvalidation_0-mlogloss:0.34316\n",
      "[624]\tvalidation_0-mlogloss:0.34314\n",
      "[625]\tvalidation_0-mlogloss:0.34311\n",
      "[626]\tvalidation_0-mlogloss:0.34304\n",
      "[627]\tvalidation_0-mlogloss:0.34301\n",
      "[628]\tvalidation_0-mlogloss:0.34299\n",
      "[629]\tvalidation_0-mlogloss:0.34298\n",
      "[630]\tvalidation_0-mlogloss:0.34298\n",
      "[631]\tvalidation_0-mlogloss:0.34299\n",
      "[632]\tvalidation_0-mlogloss:0.34293\n",
      "[633]\tvalidation_0-mlogloss:0.34292\n",
      "[634]\tvalidation_0-mlogloss:0.34291\n",
      "[635]\tvalidation_0-mlogloss:0.34286\n",
      "[636]\tvalidation_0-mlogloss:0.34285\n",
      "[637]\tvalidation_0-mlogloss:0.34286\n",
      "[638]\tvalidation_0-mlogloss:0.34285\n",
      "[639]\tvalidation_0-mlogloss:0.34282\n",
      "[640]\tvalidation_0-mlogloss:0.34279\n",
      "[641]\tvalidation_0-mlogloss:0.34277\n",
      "[642]\tvalidation_0-mlogloss:0.34273\n",
      "[643]\tvalidation_0-mlogloss:0.34270\n",
      "[644]\tvalidation_0-mlogloss:0.34268\n",
      "[645]\tvalidation_0-mlogloss:0.34266\n",
      "[646]\tvalidation_0-mlogloss:0.34264\n",
      "[647]\tvalidation_0-mlogloss:0.34264\n",
      "[648]\tvalidation_0-mlogloss:0.34263\n",
      "[649]\tvalidation_0-mlogloss:0.34260\n",
      "[650]\tvalidation_0-mlogloss:0.34255\n",
      "[651]\tvalidation_0-mlogloss:0.34254\n",
      "[652]\tvalidation_0-mlogloss:0.34257\n",
      "[653]\tvalidation_0-mlogloss:0.34254\n",
      "[654]\tvalidation_0-mlogloss:0.34253\n",
      "[655]\tvalidation_0-mlogloss:0.34252\n",
      "[656]\tvalidation_0-mlogloss:0.34251\n",
      "[657]\tvalidation_0-mlogloss:0.34251\n",
      "[658]\tvalidation_0-mlogloss:0.34248\n",
      "[659]\tvalidation_0-mlogloss:0.34247\n",
      "[660]\tvalidation_0-mlogloss:0.34245\n",
      "[661]\tvalidation_0-mlogloss:0.34243\n",
      "[662]\tvalidation_0-mlogloss:0.34241\n",
      "[663]\tvalidation_0-mlogloss:0.34239\n",
      "[664]\tvalidation_0-mlogloss:0.34240\n",
      "[665]\tvalidation_0-mlogloss:0.34237\n",
      "[666]\tvalidation_0-mlogloss:0.34235\n",
      "[667]\tvalidation_0-mlogloss:0.34233\n",
      "[668]\tvalidation_0-mlogloss:0.34231\n",
      "[669]\tvalidation_0-mlogloss:0.34228\n",
      "[670]\tvalidation_0-mlogloss:0.34225\n",
      "[671]\tvalidation_0-mlogloss:0.34224\n",
      "[672]\tvalidation_0-mlogloss:0.34225\n",
      "[673]\tvalidation_0-mlogloss:0.34224\n",
      "[674]\tvalidation_0-mlogloss:0.34221\n",
      "[675]\tvalidation_0-mlogloss:0.34218\n",
      "[676]\tvalidation_0-mlogloss:0.34216\n",
      "[677]\tvalidation_0-mlogloss:0.34214\n",
      "[678]\tvalidation_0-mlogloss:0.34212\n",
      "[679]\tvalidation_0-mlogloss:0.34210\n",
      "[680]\tvalidation_0-mlogloss:0.34208\n",
      "[681]\tvalidation_0-mlogloss:0.34206\n",
      "[682]\tvalidation_0-mlogloss:0.34204\n",
      "[683]\tvalidation_0-mlogloss:0.34203\n",
      "[684]\tvalidation_0-mlogloss:0.34200\n",
      "[685]\tvalidation_0-mlogloss:0.34200\n",
      "[686]\tvalidation_0-mlogloss:0.34197\n",
      "[687]\tvalidation_0-mlogloss:0.34198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[688]\tvalidation_0-mlogloss:0.34193\n",
      "[689]\tvalidation_0-mlogloss:0.34193\n",
      "[690]\tvalidation_0-mlogloss:0.34189\n",
      "[691]\tvalidation_0-mlogloss:0.34188\n",
      "[692]\tvalidation_0-mlogloss:0.34185\n",
      "[693]\tvalidation_0-mlogloss:0.34183\n",
      "[694]\tvalidation_0-mlogloss:0.34182\n",
      "[695]\tvalidation_0-mlogloss:0.34179\n",
      "[696]\tvalidation_0-mlogloss:0.34178\n",
      "[697]\tvalidation_0-mlogloss:0.34176\n",
      "[698]\tvalidation_0-mlogloss:0.34176\n",
      "[699]\tvalidation_0-mlogloss:0.34175\n",
      "[700]\tvalidation_0-mlogloss:0.34172\n",
      "[701]\tvalidation_0-mlogloss:0.34172\n",
      "[702]\tvalidation_0-mlogloss:0.34169\n",
      "[703]\tvalidation_0-mlogloss:0.34167\n",
      "[704]\tvalidation_0-mlogloss:0.34164\n",
      "[705]\tvalidation_0-mlogloss:0.34163\n",
      "[706]\tvalidation_0-mlogloss:0.34162\n",
      "[707]\tvalidation_0-mlogloss:0.34160\n",
      "[708]\tvalidation_0-mlogloss:0.34160\n",
      "[709]\tvalidation_0-mlogloss:0.34162\n",
      "[710]\tvalidation_0-mlogloss:0.34159\n",
      "[711]\tvalidation_0-mlogloss:0.34155\n",
      "[712]\tvalidation_0-mlogloss:0.34151\n",
      "[713]\tvalidation_0-mlogloss:0.34151\n",
      "[714]\tvalidation_0-mlogloss:0.34146\n",
      "[715]\tvalidation_0-mlogloss:0.34145\n",
      "[716]\tvalidation_0-mlogloss:0.34142\n",
      "[717]\tvalidation_0-mlogloss:0.34143\n",
      "[718]\tvalidation_0-mlogloss:0.34142\n",
      "[719]\tvalidation_0-mlogloss:0.34141\n",
      "[720]\tvalidation_0-mlogloss:0.34139\n",
      "[721]\tvalidation_0-mlogloss:0.34137\n",
      "[722]\tvalidation_0-mlogloss:0.34132\n",
      "[723]\tvalidation_0-mlogloss:0.34132\n",
      "[724]\tvalidation_0-mlogloss:0.34129\n",
      "[725]\tvalidation_0-mlogloss:0.34126\n",
      "[726]\tvalidation_0-mlogloss:0.34122\n",
      "[727]\tvalidation_0-mlogloss:0.34121\n",
      "[728]\tvalidation_0-mlogloss:0.34120\n",
      "[729]\tvalidation_0-mlogloss:0.34118\n",
      "[730]\tvalidation_0-mlogloss:0.34117\n",
      "[731]\tvalidation_0-mlogloss:0.34117\n",
      "[732]\tvalidation_0-mlogloss:0.34115\n",
      "[733]\tvalidation_0-mlogloss:0.34110\n",
      "[734]\tvalidation_0-mlogloss:0.34109\n",
      "[735]\tvalidation_0-mlogloss:0.34109\n",
      "[736]\tvalidation_0-mlogloss:0.34107\n",
      "[737]\tvalidation_0-mlogloss:0.34102\n",
      "[738]\tvalidation_0-mlogloss:0.34099\n",
      "[739]\tvalidation_0-mlogloss:0.34098\n",
      "[740]\tvalidation_0-mlogloss:0.34090\n",
      "[741]\tvalidation_0-mlogloss:0.34089\n",
      "[742]\tvalidation_0-mlogloss:0.34088\n",
      "[743]\tvalidation_0-mlogloss:0.34090\n",
      "[744]\tvalidation_0-mlogloss:0.34087\n",
      "[745]\tvalidation_0-mlogloss:0.34085\n",
      "[746]\tvalidation_0-mlogloss:0.34083\n",
      "[747]\tvalidation_0-mlogloss:0.34082\n",
      "[748]\tvalidation_0-mlogloss:0.34083\n",
      "[749]\tvalidation_0-mlogloss:0.34081\n",
      "[750]\tvalidation_0-mlogloss:0.34077\n",
      "[751]\tvalidation_0-mlogloss:0.34074\n",
      "[752]\tvalidation_0-mlogloss:0.34074\n",
      "[753]\tvalidation_0-mlogloss:0.34073\n",
      "[754]\tvalidation_0-mlogloss:0.34071\n",
      "[755]\tvalidation_0-mlogloss:0.34073\n",
      "[756]\tvalidation_0-mlogloss:0.34070\n",
      "[757]\tvalidation_0-mlogloss:0.34065\n",
      "[758]\tvalidation_0-mlogloss:0.34065\n",
      "[759]\tvalidation_0-mlogloss:0.34063\n",
      "[760]\tvalidation_0-mlogloss:0.34058\n",
      "[761]\tvalidation_0-mlogloss:0.34057\n",
      "[762]\tvalidation_0-mlogloss:0.34054\n",
      "[763]\tvalidation_0-mlogloss:0.34053\n",
      "[764]\tvalidation_0-mlogloss:0.34053\n",
      "[765]\tvalidation_0-mlogloss:0.34052\n",
      "[766]\tvalidation_0-mlogloss:0.34053\n",
      "[767]\tvalidation_0-mlogloss:0.34051\n",
      "[768]\tvalidation_0-mlogloss:0.34048\n",
      "[769]\tvalidation_0-mlogloss:0.34045\n",
      "[770]\tvalidation_0-mlogloss:0.34045\n",
      "[771]\tvalidation_0-mlogloss:0.34039\n",
      "[772]\tvalidation_0-mlogloss:0.34042\n",
      "[773]\tvalidation_0-mlogloss:0.34037\n",
      "[774]\tvalidation_0-mlogloss:0.34035\n",
      "[775]\tvalidation_0-mlogloss:0.34034\n",
      "[776]\tvalidation_0-mlogloss:0.34035\n",
      "[777]\tvalidation_0-mlogloss:0.34035\n",
      "[778]\tvalidation_0-mlogloss:0.34030\n",
      "[779]\tvalidation_0-mlogloss:0.34028\n",
      "[780]\tvalidation_0-mlogloss:0.34024\n",
      "[781]\tvalidation_0-mlogloss:0.34022\n",
      "[782]\tvalidation_0-mlogloss:0.34015\n",
      "[783]\tvalidation_0-mlogloss:0.34016\n",
      "[784]\tvalidation_0-mlogloss:0.34013\n",
      "[785]\tvalidation_0-mlogloss:0.34010\n",
      "[786]\tvalidation_0-mlogloss:0.34009\n",
      "[787]\tvalidation_0-mlogloss:0.34007\n",
      "[788]\tvalidation_0-mlogloss:0.34002\n",
      "[789]\tvalidation_0-mlogloss:0.33997\n",
      "[790]\tvalidation_0-mlogloss:0.33997\n",
      "[791]\tvalidation_0-mlogloss:0.33995\n",
      "[792]\tvalidation_0-mlogloss:0.33993\n",
      "[793]\tvalidation_0-mlogloss:0.33990\n",
      "[794]\tvalidation_0-mlogloss:0.33986\n",
      "[795]\tvalidation_0-mlogloss:0.33986\n",
      "[796]\tvalidation_0-mlogloss:0.33984\n",
      "[797]\tvalidation_0-mlogloss:0.33984\n",
      "[798]\tvalidation_0-mlogloss:0.33984\n",
      "[799]\tvalidation_0-mlogloss:0.33983\n",
      "[800]\tvalidation_0-mlogloss:0.33984\n",
      "[801]\tvalidation_0-mlogloss:0.33981\n",
      "[802]\tvalidation_0-mlogloss:0.33982\n",
      "[803]\tvalidation_0-mlogloss:0.33981\n",
      "[804]\tvalidation_0-mlogloss:0.33981\n",
      "[805]\tvalidation_0-mlogloss:0.33981\n",
      "[806]\tvalidation_0-mlogloss:0.33981\n",
      "[807]\tvalidation_0-mlogloss:0.33980\n",
      "[808]\tvalidation_0-mlogloss:0.33977\n",
      "[809]\tvalidation_0-mlogloss:0.33974\n",
      "[810]\tvalidation_0-mlogloss:0.33970\n",
      "[811]\tvalidation_0-mlogloss:0.33971\n",
      "[812]\tvalidation_0-mlogloss:0.33967\n",
      "[813]\tvalidation_0-mlogloss:0.33966\n",
      "[814]\tvalidation_0-mlogloss:0.33966\n",
      "[815]\tvalidation_0-mlogloss:0.33965\n",
      "[816]\tvalidation_0-mlogloss:0.33965\n",
      "[817]\tvalidation_0-mlogloss:0.33965\n",
      "[818]\tvalidation_0-mlogloss:0.33965\n",
      "[819]\tvalidation_0-mlogloss:0.33968\n",
      "[820]\tvalidation_0-mlogloss:0.33965\n",
      "[821]\tvalidation_0-mlogloss:0.33961\n",
      "[822]\tvalidation_0-mlogloss:0.33962\n",
      "[823]\tvalidation_0-mlogloss:0.33960\n",
      "[824]\tvalidation_0-mlogloss:0.33958\n",
      "[825]\tvalidation_0-mlogloss:0.33959\n",
      "[826]\tvalidation_0-mlogloss:0.33962\n",
      "[827]\tvalidation_0-mlogloss:0.33960\n",
      "[828]\tvalidation_0-mlogloss:0.33961\n",
      "[829]\tvalidation_0-mlogloss:0.33960\n",
      "[830]\tvalidation_0-mlogloss:0.33958\n",
      "[831]\tvalidation_0-mlogloss:0.33957\n",
      "[832]\tvalidation_0-mlogloss:0.33957\n",
      "[833]\tvalidation_0-mlogloss:0.33959\n",
      "[834]\tvalidation_0-mlogloss:0.33957\n",
      "[835]\tvalidation_0-mlogloss:0.33956\n",
      "[836]\tvalidation_0-mlogloss:0.33955\n",
      "[837]\tvalidation_0-mlogloss:0.33954\n",
      "[838]\tvalidation_0-mlogloss:0.33951\n",
      "[839]\tvalidation_0-mlogloss:0.33950\n",
      "[840]\tvalidation_0-mlogloss:0.33947\n",
      "[841]\tvalidation_0-mlogloss:0.33946\n",
      "[842]\tvalidation_0-mlogloss:0.33948\n",
      "[843]\tvalidation_0-mlogloss:0.33947\n",
      "[844]\tvalidation_0-mlogloss:0.33947\n",
      "[845]\tvalidation_0-mlogloss:0.33949\n",
      "[846]\tvalidation_0-mlogloss:0.33949\n",
      "[847]\tvalidation_0-mlogloss:0.33946\n",
      "[848]\tvalidation_0-mlogloss:0.33949\n",
      "[849]\tvalidation_0-mlogloss:0.33949\n",
      "[850]\tvalidation_0-mlogloss:0.33947\n",
      "[851]\tvalidation_0-mlogloss:0.33947\n",
      "[852]\tvalidation_0-mlogloss:0.33946\n",
      "[853]\tvalidation_0-mlogloss:0.33947\n",
      "[854]\tvalidation_0-mlogloss:0.33945\n",
      "[855]\tvalidation_0-mlogloss:0.33947\n",
      "[856]\tvalidation_0-mlogloss:0.33948\n",
      "[857]\tvalidation_0-mlogloss:0.33949\n",
      "[858]\tvalidation_0-mlogloss:0.33950\n",
      "[859]\tvalidation_0-mlogloss:0.33945\n",
      "[860]\tvalidation_0-mlogloss:0.33942\n",
      "[861]\tvalidation_0-mlogloss:0.33939\n",
      "[862]\tvalidation_0-mlogloss:0.33936\n",
      "[863]\tvalidation_0-mlogloss:0.33934\n",
      "[864]\tvalidation_0-mlogloss:0.33934\n",
      "[865]\tvalidation_0-mlogloss:0.33934\n",
      "[866]\tvalidation_0-mlogloss:0.33932\n",
      "[867]\tvalidation_0-mlogloss:0.33932\n",
      "[868]\tvalidation_0-mlogloss:0.33931\n",
      "[869]\tvalidation_0-mlogloss:0.33930\n",
      "[870]\tvalidation_0-mlogloss:0.33928\n",
      "[871]\tvalidation_0-mlogloss:0.33926\n",
      "[872]\tvalidation_0-mlogloss:0.33919\n",
      "[873]\tvalidation_0-mlogloss:0.33916\n",
      "[874]\tvalidation_0-mlogloss:0.33915\n",
      "[875]\tvalidation_0-mlogloss:0.33914\n",
      "[876]\tvalidation_0-mlogloss:0.33914\n",
      "[877]\tvalidation_0-mlogloss:0.33915\n",
      "[878]\tvalidation_0-mlogloss:0.33912\n",
      "[879]\tvalidation_0-mlogloss:0.33911\n",
      "[880]\tvalidation_0-mlogloss:0.33909\n",
      "[881]\tvalidation_0-mlogloss:0.33909\n",
      "[882]\tvalidation_0-mlogloss:0.33910\n",
      "[883]\tvalidation_0-mlogloss:0.33908\n",
      "[884]\tvalidation_0-mlogloss:0.33908\n",
      "[885]\tvalidation_0-mlogloss:0.33907\n",
      "[886]\tvalidation_0-mlogloss:0.33906\n",
      "[887]\tvalidation_0-mlogloss:0.33905\n",
      "[888]\tvalidation_0-mlogloss:0.33904\n",
      "[889]\tvalidation_0-mlogloss:0.33905\n",
      "[890]\tvalidation_0-mlogloss:0.33904\n",
      "[891]\tvalidation_0-mlogloss:0.33904\n",
      "[892]\tvalidation_0-mlogloss:0.33902\n",
      "[893]\tvalidation_0-mlogloss:0.33898\n",
      "[894]\tvalidation_0-mlogloss:0.33897\n",
      "[895]\tvalidation_0-mlogloss:0.33894\n",
      "[896]\tvalidation_0-mlogloss:0.33893\n",
      "[897]\tvalidation_0-mlogloss:0.33889\n",
      "[898]\tvalidation_0-mlogloss:0.33887\n",
      "[899]\tvalidation_0-mlogloss:0.33887\n",
      "[900]\tvalidation_0-mlogloss:0.33886\n",
      "[901]\tvalidation_0-mlogloss:0.33883\n",
      "[902]\tvalidation_0-mlogloss:0.33880\n",
      "[903]\tvalidation_0-mlogloss:0.33879\n",
      "[904]\tvalidation_0-mlogloss:0.33879\n",
      "[905]\tvalidation_0-mlogloss:0.33878\n",
      "[906]\tvalidation_0-mlogloss:0.33877\n",
      "[907]\tvalidation_0-mlogloss:0.33877\n",
      "[908]\tvalidation_0-mlogloss:0.33873\n",
      "[909]\tvalidation_0-mlogloss:0.33876\n",
      "[910]\tvalidation_0-mlogloss:0.33875\n",
      "[911]\tvalidation_0-mlogloss:0.33876\n",
      "[912]\tvalidation_0-mlogloss:0.33876\n",
      "[913]\tvalidation_0-mlogloss:0.33874\n",
      "[914]\tvalidation_0-mlogloss:0.33875\n",
      "[915]\tvalidation_0-mlogloss:0.33872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[916]\tvalidation_0-mlogloss:0.33873\n",
      "[917]\tvalidation_0-mlogloss:0.33870\n",
      "[918]\tvalidation_0-mlogloss:0.33873\n",
      "[919]\tvalidation_0-mlogloss:0.33869\n",
      "[920]\tvalidation_0-mlogloss:0.33869\n",
      "[921]\tvalidation_0-mlogloss:0.33866\n",
      "[922]\tvalidation_0-mlogloss:0.33864\n",
      "[923]\tvalidation_0-mlogloss:0.33862\n",
      "[924]\tvalidation_0-mlogloss:0.33862\n",
      "[925]\tvalidation_0-mlogloss:0.33860\n",
      "[926]\tvalidation_0-mlogloss:0.33858\n",
      "[927]\tvalidation_0-mlogloss:0.33859\n",
      "[928]\tvalidation_0-mlogloss:0.33857\n",
      "[929]\tvalidation_0-mlogloss:0.33854\n",
      "[930]\tvalidation_0-mlogloss:0.33854\n",
      "[931]\tvalidation_0-mlogloss:0.33852\n",
      "[932]\tvalidation_0-mlogloss:0.33852\n",
      "[933]\tvalidation_0-mlogloss:0.33852\n",
      "[934]\tvalidation_0-mlogloss:0.33854\n",
      "[935]\tvalidation_0-mlogloss:0.33854\n",
      "[936]\tvalidation_0-mlogloss:0.33855\n",
      "[937]\tvalidation_0-mlogloss:0.33854\n",
      "[938]\tvalidation_0-mlogloss:0.33852\n",
      "[939]\tvalidation_0-mlogloss:0.33850\n",
      "[940]\tvalidation_0-mlogloss:0.33851\n",
      "[941]\tvalidation_0-mlogloss:0.33850\n",
      "[942]\tvalidation_0-mlogloss:0.33852\n",
      "[943]\tvalidation_0-mlogloss:0.33852\n",
      "[944]\tvalidation_0-mlogloss:0.33850\n",
      "[945]\tvalidation_0-mlogloss:0.33847\n",
      "[946]\tvalidation_0-mlogloss:0.33845\n",
      "[947]\tvalidation_0-mlogloss:0.33844\n",
      "[948]\tvalidation_0-mlogloss:0.33844\n",
      "[949]\tvalidation_0-mlogloss:0.33842\n",
      "[950]\tvalidation_0-mlogloss:0.33841\n",
      "[951]\tvalidation_0-mlogloss:0.33839\n",
      "[952]\tvalidation_0-mlogloss:0.33841\n",
      "[953]\tvalidation_0-mlogloss:0.33838\n",
      "[954]\tvalidation_0-mlogloss:0.33836\n",
      "[955]\tvalidation_0-mlogloss:0.33837\n",
      "[956]\tvalidation_0-mlogloss:0.33836\n",
      "[957]\tvalidation_0-mlogloss:0.33836\n",
      "[958]\tvalidation_0-mlogloss:0.33834\n",
      "[959]\tvalidation_0-mlogloss:0.33832\n",
      "[960]\tvalidation_0-mlogloss:0.33831\n",
      "[961]\tvalidation_0-mlogloss:0.33832\n",
      "[962]\tvalidation_0-mlogloss:0.33832\n",
      "[963]\tvalidation_0-mlogloss:0.33830\n",
      "[964]\tvalidation_0-mlogloss:0.33832\n",
      "[965]\tvalidation_0-mlogloss:0.33832\n",
      "[966]\tvalidation_0-mlogloss:0.33830\n",
      "[967]\tvalidation_0-mlogloss:0.33828\n",
      "[968]\tvalidation_0-mlogloss:0.33828\n",
      "[969]\tvalidation_0-mlogloss:0.33826\n",
      "[970]\tvalidation_0-mlogloss:0.33824\n",
      "[971]\tvalidation_0-mlogloss:0.33821\n",
      "[972]\tvalidation_0-mlogloss:0.33820\n",
      "[973]\tvalidation_0-mlogloss:0.33819\n",
      "[974]\tvalidation_0-mlogloss:0.33820\n",
      "[975]\tvalidation_0-mlogloss:0.33817\n",
      "[976]\tvalidation_0-mlogloss:0.33816\n",
      "[977]\tvalidation_0-mlogloss:0.33816\n",
      "[978]\tvalidation_0-mlogloss:0.33815\n",
      "[979]\tvalidation_0-mlogloss:0.33815\n",
      "[980]\tvalidation_0-mlogloss:0.33811\n",
      "[981]\tvalidation_0-mlogloss:0.33812\n",
      "[982]\tvalidation_0-mlogloss:0.33812\n",
      "[983]\tvalidation_0-mlogloss:0.33810\n",
      "[984]\tvalidation_0-mlogloss:0.33810\n",
      "[985]\tvalidation_0-mlogloss:0.33810\n",
      "[986]\tvalidation_0-mlogloss:0.33808\n",
      "[987]\tvalidation_0-mlogloss:0.33808\n",
      "[988]\tvalidation_0-mlogloss:0.33807\n",
      "[989]\tvalidation_0-mlogloss:0.33805\n",
      "[990]\tvalidation_0-mlogloss:0.33803\n",
      "[991]\tvalidation_0-mlogloss:0.33803\n",
      "[992]\tvalidation_0-mlogloss:0.33799\n",
      "[993]\tvalidation_0-mlogloss:0.33800\n",
      "[994]\tvalidation_0-mlogloss:0.33799\n",
      "[995]\tvalidation_0-mlogloss:0.33797\n",
      "[996]\tvalidation_0-mlogloss:0.33798\n",
      "[997]\tvalidation_0-mlogloss:0.33797\n",
      "[998]\tvalidation_0-mlogloss:0.33795\n",
      "[999]\tvalidation_0-mlogloss:0.33796\n",
      "Saving XGBoost model to hallucination_xgb_model.json\n",
      "Saving feature pipeline to hallucination_feature_pipeline.pkl\n",
      "Validation accuracy: 0.8233\n"
     ]
    }
   ],
   "source": [
    "feature_pipeline, xgb_model = train_xgboost_model(train_data, val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095af4d4",
   "metadata": {},
   "source": [
    "### 8. Evaluate GPT-4 (Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fdb2a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating standard LLM approach with sample size 100...\n",
      "Getting LLM predictions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:11<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard approach accuracy: 0.4500\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.38      1.00      0.55        33\n",
      "           0       1.00      0.31      0.48        35\n",
      "           1       1.00      0.03      0.06        32\n",
      "\n",
      "    accuracy                           0.45       100\n",
      "   macro avg       0.79      0.45      0.36       100\n",
      "weighted avg       0.79      0.45      0.37       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "standard_results, standard_accuracy = evaluate_standard_approach(test_data, sample_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0873c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating standard LLM approach with sample size 500 using batch size 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [05:46<00:00, 13.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standard approach accuracy (sample size 500): 0.4080\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      0.99      0.52       162\n",
      "           0       0.92      0.20      0.33       171\n",
      "           1       1.00      0.05      0.09       167\n",
      "\n",
      "    accuracy                           0.41       500\n",
      "   macro avg       0.76      0.42      0.32       500\n",
      "weighted avg       0.76      0.41      0.31       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "standard_results_500, acc_standard_500 = evaluate_standard_approach_batched(test_data, sample_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38ef77",
   "metadata": {},
   "source": [
    "### 9. Evaluate GPT-4 + RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "660e18f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RAG-enhanced LLM approach with sample size 100 using batch size 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 2 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 3 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 1 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 2 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 3 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 1 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 2 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 3 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 1 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 2 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 3 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 1 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 2 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 3 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 1 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 2 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 3 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 1 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 2 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 3 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 1 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n",
      "Attempt 2 failed: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/5 [01:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 55\u001b[0m, in \u001b[0;36mquery_llm_with_retry\u001b[0;34m(prompt, model, max_retries, delay)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 55\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mChatCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     56\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     57\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     59\u001b[0m     content \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m (\n\u001b[1;32m    139\u001b[0m     deployment_id,\n\u001b[1;32m    140\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m response, _, api_key \u001b[38;5;241m=\u001b[39m requestor\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m     url,\n\u001b[1;32m    156\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    157\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    158\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m    159\u001b[0m     request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[1;32m    160\u001b[0m     request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    288\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m     method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m     request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m )\n\u001b[0;32m--> 298\u001b[0m resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    702\u001b[0m             result\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rag_results, rag_accuracy \u001b[38;5;241m=\u001b[39m evaluate_rag_approach_batched(test_data, sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[53], line 131\u001b[0m, in \u001b[0;36mevaluate_rag_approach_batched\u001b[0;34m(test_data, sample_size, batch_size)\u001b[0m\n\u001b[1;32m    129\u001b[0m     batch \u001b[38;5;241m=\u001b[39m sample_data\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrag_prompt\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 131\u001b[0m         response \u001b[38;5;241m=\u001b[39m query_llm_with_retry(prompt)\n\u001b[1;32m    132\u001b[0m         rag_llm_responses\u001b[38;5;241m.\u001b[39mappend(response)\n\u001b[1;32m    134\u001b[0m sample_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrag_llm_response\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m rag_llm_responses\n",
      "Cell \u001b[0;32mIn[53], line 65\u001b[0m, in \u001b[0;36mquery_llm_with_retry\u001b[0;34m(prompt, model, max_retries, delay)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m<\u001b[39m max_retries \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(delay)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI Error\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "rag_results, rag_accuracy = evaluate_rag_approach_batched(test_data, sample_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aad3c761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RAG-enhanced LLM approach with sample size 500 using batch size 20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [05:16<00:00, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAG-enhanced approach accuracy (sample size 500): 0.4440\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      0.97      0.53       162\n",
      "           0       0.84      0.24      0.37       171\n",
      "           1       0.96      0.14      0.25       167\n",
      "\n",
      "    accuracy                           0.44       500\n",
      "   macro avg       0.72      0.45      0.39       500\n",
      "weighted avg       0.73      0.44      0.38       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rag_results_500, acc_rag_500 = evaluate_rag_approach_batched(test_data, sample_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465962c6",
   "metadata": {},
   "source": [
    "### 10. Save LLM Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fca6c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CACHE_FILE = \"/Users/shubhamgaur/Desktop/NU/Sem4/IR/Project/Milestone2/llm_response_cache.json\"\n",
    "with open(CACHE_FILE, \"w\") as f:\n",
    "    json.dump(llm_cache, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002caa39",
   "metadata": {},
   "source": [
    "### 11. Evaluate Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a385239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ensemble approach...\n",
      "\n",
      "Ensemble approach accuracy: 0.4800\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.39      0.97      0.55        33\n",
      "           0       0.93      0.37      0.53        35\n",
      "           1       1.00      0.09      0.17        32\n",
      "\n",
      "    accuracy                           0.48       100\n",
      "   macro avg       0.77      0.48      0.42       100\n",
      "weighted avg       0.77      0.48      0.42       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ensemble_results, ensemble_accuracy = evaluate_ensemble_approach(\n",
    "    test_data, ml_model, rag_results, sample_size=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c83a9b86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rag_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ensemble_results, ensemble_accuracy \u001b[38;5;241m=\u001b[39m evaluate_ensemble_approach_batched(\n\u001b[0;32m----> 2\u001b[0m     test_data, xgb_model, rag_results, sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rag_results' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "ensemble_results, ensemble_accuracy = evaluate_ensemble_approach_batched(\n",
    "    test_data, xgb_model, rag_results, sample_size=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "609e2571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Ensemble approach with sample size 500...\n",
      "\n",
      "Ensemble approach accuracy (sample size 500): 0.4440\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.37      0.97      0.53       162\n",
      "           0       0.84      0.24      0.37       171\n",
      "           1       0.96      0.14      0.25       167\n",
      "\n",
      "    accuracy                           0.44       500\n",
      "   macro avg       0.72      0.45      0.39       500\n",
      "weighted avg       0.73      0.44      0.38       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble_results_500, acc_ensemble_500 = evaluate_ensemble_approach_batched(\n",
    "    test_data, ml_model, rag_results_500, sample_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b4e6c9",
   "metadata": {},
   "source": [
    "### 12. Visualize Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89763549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracies = [\n",
    "    standard_accuracy,\n",
    "    rag_accuracy,\n",
    "    ensemble_accuracy\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(['Standard', 'RAG-Enhanced', 'Ensemble'], accuracies, color=plt.cm.Set2.colors[:len(method_names)])\n",
    "plt.title('Hallucination Detection Accuracy by Method')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "for i, acc in enumerate(accuracies):\n",
    "    plt.text(i, acc + 0.02, f'{acc:.4f}', ha='center')\n",
    "plt.tight_layout()\n",
    "plt.savefig('hallucination_detection_results.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fa730342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dictionary of method names and their corresponding accuracies\n",
    "accuracy_dict = {\n",
    "    'Standard': acc_standard_500,\n",
    "    'RAG-Enhanced': acc_rag_500,\n",
    "    'Ensemble': acc_ensemble_500,\n",
    "    # Add more methods here if needed\n",
    "}\n",
    "\n",
    "# Extract names and values in the correct order\n",
    "method_names = list(accuracy_dict.keys())\n",
    "accuracies = list(accuracy_dict.values())\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(method_names, accuracies, color=plt.cm.Set2.colors[:len(method_names)])\n",
    "plt.title('Hallucination Detection Accuracy by Method 500 Samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1.0)\n",
    "\n",
    "# Annotate accuracy values on bars\n",
    "for i, acc in enumerate(accuracies):\n",
    "    plt.text(i, acc + 0.02, f'{acc:.4f}', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hallucination_detection_results.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba4ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abbf929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_hallucination_detection_pipeline(file_path, balanced=True, sample_size=100):\n",
    "#     \"\"\"Run the complete hallucination detection pipeline.\"\"\"\n",
    "#     # Set up OpenAI API key\n",
    "#     openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "#     if not openai.api_key:\n",
    "#         print(\"Warning: OpenAI API key not found in environment variables\")\n",
    "#         openai.api_key = input(\"Please enter your OpenAI API key: \")\n",
    "    \n",
    "#     # Step 1: Process data\n",
    "#     df = process_fever_data(file_path, balanced_sampling=balanced)\n",
    "    \n",
    "#     # Step 2: Split data\n",
    "#     train_data, val_data, test_data = create_train_val_test_split(df)\n",
    "    \n",
    "#     # Step 3: Add NLP features\n",
    "#     train_data, val_data, test_data = add_nlp_features(train_data, val_data, test_data)\n",
    "    \n",
    "#     # Step 4: Set up RAG system\n",
    "#     vector_store = setup_rag_system(train_data)\n",
    "    \n",
    "#     # Step 5: Augment test data with RAG\n",
    "#     test_data = augment_evidence_with_rag(test_data, vector_store)\n",
    "    \n",
    "#     # Step 6: Train ML model\n",
    "#     ml_model = train_ml_model(train_data, val_data)\n",
    "    \n",
    "#     # Step 7: Evaluate standard approach\n",
    "#     standard_results, standard_accuracy = evaluate_standard_approach(test_data, sample_size=sample_size)\n",
    "    \n",
    "#     # Step 8: Evaluate RAG approach\n",
    "#     rag_results, rag_accuracy = evaluate_rag_approach(test_data, sample_size=sample_size)\n",
    "    \n",
    "#     # Save cached LLM responses to file\n",
    "#     with open(CACHE_FILE, \"w\") as f:\n",
    "#         json.dump(llm_cache, f, indent=2)\n",
    "    \n",
    "#     # Step 9: Evaluate ensemble approach\n",
    "#     ensemble_results, ensemble_accuracy = evaluate_ensemble_approach(test_data, ml_model, rag_results, sample_size=sample_size)\n",
    "    \n",
    "#     # Step 10: Print summary\n",
    "#     print(\"\\n=== Hallucination Detection Results ===\")\n",
    "#     print(f\"Standard approach accuracy: {standard_accuracy:.4f}\")\n",
    "#     print(f\"RAG-enhanced approach accuracy: {rag_accuracy:.4f}\")\n",
    "#     print(f\"Ensemble approach accuracy: {ensemble_accuracy:.4f}\")\n",
    "    \n",
    "#     return {\n",
    "#         'train_data': train_data,\n",
    "#         'val_data': val_data,\n",
    "#         'test_data': test_data,\n",
    "#         'ml_model': ml_model,\n",
    "#         'vector_store': vector_store,\n",
    "#         'standard_results': standard_results,\n",
    "#         'rag_results': rag_results,\n",
    "#         'ensemble_results': ensemble_results,\n",
    "#         'accuracies': {\n",
    "#             'standard': standard_accuracy,\n",
    "#             'rag': rag_accuracy,\n",
    "#             'ensemble': ensemble_accuracy\n",
    "#         }\n",
    "#     }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec32525",
   "metadata": {},
   "source": [
    "## Main execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2e974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Example usage:\n",
    "#     results = run_hallucination_detection_pipeline(\n",
    "#         file_path=\"/Users/shubhamgaur/Desktop/NU/Sem4/IR/Project/Milestone2/train.jsonl\",\n",
    "#         balanced=True,\n",
    "#         sample_size=100\n",
    "#     )\n",
    "    \n",
    "#     # Optional: Visualize results\n",
    "#     accuracies = [\n",
    "#         results['accuracies']['standard'],\n",
    "#         results['accuracies']['rag'],\n",
    "#         results['accuracies']['ensemble']\n",
    "#     ]\n",
    "    \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.bar(['Standard', 'RAG-Enhanced', 'Ensemble'], accuracies, color=['blue', 'green', 'red'])\n",
    "#     plt.title('Hallucination Detection Accuracy by Method')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.ylim(0, 1.0)\n",
    "#     for i, acc in enumerate(accuracies):\n",
    "#         plt.text(i, acc + 0.02, f'{acc:.4f}', ha='center')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('hallucination_detection_results.png')\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
